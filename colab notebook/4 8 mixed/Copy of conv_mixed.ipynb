{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of conv_mixed.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KEO20Jag-R8J","colab_type":"code","outputId":"805a0694-09ab-403f-f631-3eec47394949","executionInfo":{"status":"ok","timestamp":1574860877995,"user_tz":-540,"elapsed":59286,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# To install fairseq from source and develop locally:\n","!git clone https://github.com/choyi0521/fairseq\n","%cd /content/fairseq\n","!pip install --editable ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 12164, done.\u001b[K\n","remote: Total 12164 (delta 0), reused 0 (delta 0), pack-reused 12164\u001b[K\n","Receiving objects: 100% (12164/12164), 5.69 MiB | 7.26 MiB/s, done.\n","Resolving deltas: 100% (8955/8955), done.\n","/content/fairseq\n","Obtaining file:///content/fairseq\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.13.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (0.29.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.17.4)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 7.8MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (4.28.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.8.0) (2.19)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.8.0) (3.6.6)\n","Installing collected packages: regex, portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.2 regex-2019.11.1 sacrebleu-1.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43JqPSHkJfQT","colab_type":"code","outputId":"9abdc2e7-460b-48de-b559-48154295aac1","executionInfo":{"status":"ok","timestamp":1574860884171,"user_tz":-540,"elapsed":65452,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!git checkout dev4\n","!git pull origin dev4"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Branch 'dev4' set up to track remote branch 'dev4' from 'origin'.\n","Switched to a new branch 'dev4'\n","From https://github.com/choyi0521/fairseq\n"," * branch            dev4       -> FETCH_HEAD\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy8_Nx2lAxp9","colab_type":"code","outputId":"67e4d6fc-f01d-444d-d12f-a87d33b52dcc","executionInfo":{"status":"ok","timestamp":1574861053697,"user_tz":-540,"elapsed":234971,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Download and prepare the data\n","%cd /content/fairseq\n","%cd examples/translation/\n","!bash prepare-iwslt14.sh\n","%cd ../..\n","\n","# Preprocess/binarize the data\n","TEXT=\"examples/translation/iwslt14.tokenized.de-en\"\n","!fairseq-preprocess --source-lang de --target-lang en \\\n","    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n","    --destdir data-bin/iwslt14.tokenized.de-en \\\n","    --workers 20"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","/content/fairseq/examples/translation\n","Cloning Moses github repository (for tokenization scripts)...\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 169, done.\u001b[K\n","remote: Counting objects: 100% (169/169), done.\u001b[K\n","remote: Compressing objects: 100% (89/89), done.\u001b[K\n","remote: Total 147464 (delta 104), reused 118 (delta 74), pack-reused 147295\u001b[K\n","Receiving objects: 100% (147464/147464), 129.73 MiB | 23.44 MiB/s, done.\n","Resolving deltas: 100% (113938/113938), done.\n","Cloning Subword NMT repository (for BPE pre-processing)...\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 538 (delta 10), reused 21 (delta 7), pack-reused 509\u001b[K\n","Receiving objects: 100% (538/538), 226.98 KiB | 851.00 KiB/s, done.\n","Resolving deltas: 100% (316/316), done.\n","Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n","--2019-11-27 13:21:36--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n","Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n","Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19982877 (19M) [application/x-gzip]\n","Saving to: ‘de-en.tgz’\n","\n","de-en.tgz           100%[===================>]  19.06M  39.8MB/s    in 0.5s    \n","\n","2019-11-27 13:21:37 (39.8 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n","\n","Data successfully downloaded.\n","de-en/\n","de-en/IWSLT14.TED.dev2010.de-en.de.xml\n","de-en/IWSLT14.TED.dev2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2010.de-en.de.xml\n","de-en/IWSLT14.TED.tst2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2011.de-en.de.xml\n","de-en/IWSLT14.TED.tst2011.de-en.en.xml\n","de-en/IWSLT14.TED.tst2012.de-en.de.xml\n","de-en/IWSLT14.TED.tst2012.de-en.en.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n","de-en/README\n","de-en/train.en\n","de-en/train.tags.de-en.de\n","de-en/train.tags.de-en.en\n","pre-processing train data...\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n","..........(100000).......\n","Input sentences: 174443  Output sentences:  167522\n","pre-processing valid/test data...\n","orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","creating train, valid, test...\n","learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n","subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","apply_bpe.py to train.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to train.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","/content/fairseq\n","Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', workers=20)\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n","| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GKekFxgwNY9K","colab_type":"code","outputId":"39437c4a-e725-43bf-fe6c-30523c4a1878","executionInfo":{"status":"ok","timestamp":1574862934463,"user_tz":-540,"elapsed":2115731,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","SAVE=\"/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt\"\n","\n","# Training\n","%cd /content/fairseq\n","!mkdir -p \"{SAVE}\" \n","!CUDA_VISIBLE_DEVICES=0 $(which fairseq-train) data-bin/iwslt14.tokenized.de-en \\\n","    --encoder-conv-type ddynamic --decoder-conv-type ddynamic \\\n","    --clip-norm 0 --optimizer adam --lr 0.0005 \\\n","    --source-lang de --target-lang en --max-tokens 4000 --no-progress-bar \\\n","    --log-interval 100 --min-lr '1e-09' --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --ddp-backend=no_c10d \\\n","    --max-update 50000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n","    --adam-betas '(0.9, 0.98)' --keep-last-epochs 10 \\\n","    -a lightconv_iwslt_de_en --save-dir \"{SAVE}\" \\\n","    --dropout 0.3 --attention-dropout 0.1 --weight-dropout 0.1 \\\n","    --encoder-glu 1 --decoder-glu 1 \\\n","    --conv-mixed 1 \\\n","    --encoder-attention-heads 4 --decoder-attention-heads 4 \\\n","    --encoder-attention-proj-heads 8 --decoder-attention-proj-heads 8 \\\n","    --encoder-layers 7 --encoder-kernel-size-list [3,7,15,31,31,31,31] \\\n","    2>&1 | tee \"{SAVE}/train3.log\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='lightconv_iwslt_de_en', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, conv_mixed=True, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=4, decoder_attention_proj_heads=8, decoder_conv_dim=512, decoder_conv_type='ddynamic', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=True, decoder_input_dim=512, decoder_kernel_size_list=[3, 7, 15, 31, 31, 31], decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_attention_proj_heads=8, encoder_conv_dim=512, encoder_conv_type='ddynamic', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=True, encoder_kernel_size_list=[3, 7, 15, 31, 31, 31, 31], encoder_layers=7, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, input_dropout=0.0, keep_interval_updates=-1, keep_last_epochs=10, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n","| data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n","LightConvModel(\n","  (encoder): LightConvEncoder(\n","    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=1, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=96, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=3, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=224, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=7, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=480, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (4): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (5): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (6): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (decoder): LightConvDecoder(\n","    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=2, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=96, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=6, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=224, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=14, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=480, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=8, conv_mixed=True, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=64, out_features=992, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model lightconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 42106368 (num. trained: 42099712)\n","| training on 1 GPUs\n","| max tokens per GPU = 4000 and max sentences per GPU = None\n","| loaded checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last.pt (epoch 39 @ 44109 updates)\n","| loading train data for epoch 39\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n","| data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n","| epoch 040:    100 / 1131 loss=2.972, nll_loss=1.416, ppl=2.67, wps=11313, ups=3, wpb=3412.040, bsz=123.723, num_updates=44210, lr=0.000150397, gnorm=0.706, clip=0.000, oom=0.000, wall=32, train_wall=13224\n","| epoch 040:    200 / 1131 loss=2.963, nll_loss=1.408, ppl=2.65, wps=11345, ups=3, wpb=3427.199, bsz=132.697, num_updates=44310, lr=0.000150227, gnorm=0.701, clip=0.000, oom=0.000, wall=62, train_wall=13254\n","| epoch 040:    300 / 1131 loss=2.971, nll_loss=1.416, ppl=2.67, wps=11374, ups=3, wpb=3446.910, bsz=131.907, num_updates=44410, lr=0.000150058, gnorm=0.702, clip=0.000, oom=0.000, wall=93, train_wall=13284\n","| epoch 040:    400 / 1131 loss=2.983, nll_loss=1.430, ppl=2.69, wps=11420, ups=3, wpb=3465.671, bsz=131.070, num_updates=44510, lr=0.000149889, gnorm=0.705, clip=0.000, oom=0.000, wall=123, train_wall=13314\n","| epoch 040:    500 / 1131 loss=2.989, nll_loss=1.437, ppl=2.71, wps=11430, ups=3, wpb=3467.411, bsz=132.772, num_updates=44610, lr=0.000149721, gnorm=0.707, clip=0.000, oom=0.000, wall=153, train_wall=13344\n","| epoch 040:    600 / 1131 loss=2.988, nll_loss=1.437, ppl=2.71, wps=11430, ups=3, wpb=3469.631, bsz=135.493, num_updates=44710, lr=0.000149554, gnorm=0.706, clip=0.000, oom=0.000, wall=184, train_wall=13374\n","| epoch 040:    700 / 1131 loss=2.988, nll_loss=1.437, ppl=2.71, wps=11424, ups=3, wpb=3474.101, bsz=137.699, num_updates=44810, lr=0.000149387, gnorm=0.704, clip=0.000, oom=0.000, wall=215, train_wall=13404\n","| epoch 040:    800 / 1131 loss=2.993, nll_loss=1.443, ppl=2.72, wps=11438, ups=3, wpb=3478.930, bsz=138.286, num_updates=44910, lr=0.00014922, gnorm=0.705, clip=0.000, oom=0.000, wall=245, train_wall=13434\n","| epoch 040:    900 / 1131 loss=2.996, nll_loss=1.447, ppl=2.73, wps=11440, ups=3, wpb=3476.736, bsz=138.982, num_updates=45010, lr=0.000149055, gnorm=0.706, clip=0.000, oom=0.000, wall=275, train_wall=13464\n","| epoch 040:   1000 / 1131 loss=3.000, nll_loss=1.451, ppl=2.73, wps=11451, ups=3, wpb=3479.652, bsz=139.388, num_updates=45110, lr=0.000148889, gnorm=0.707, clip=0.000, oom=0.000, wall=306, train_wall=13494\n","| epoch 040:   1100 / 1131 loss=3.002, nll_loss=1.455, ppl=2.74, wps=11472, ups=3, wpb=3491.003, bsz=141.856, num_updates=45210, lr=0.000148725, gnorm=0.705, clip=0.000, oom=0.000, wall=336, train_wall=13524\n","| epoch 040 | loss 3.003 | nll_loss 1.455 | ppl 2.74 | wps 11470 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 45240 | lr 0.000148675 | gnorm 0.705 | clip 0.000 | oom 0.000 | wall 346 | train_wall 13533\n","| epoch 040 | valid on 'valid' subset | loss 3.984 | nll_loss 2.424 | ppl 5.37 | num_updates 45240 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint40.pt (epoch 40 @ 45240 updates) (writing took 4.1509153842926025 seconds)\n","| epoch 041:    100 / 1131 loss=2.952, nll_loss=1.397, ppl=2.63, wps=11423, ups=3, wpb=3551.337, bsz=148.356, num_updates=45341, lr=0.00014851, gnorm=0.682, clip=0.000, oom=0.000, wall=386, train_wall=13564\n","| epoch 041:    200 / 1131 loss=2.953, nll_loss=1.398, ppl=2.63, wps=11391, ups=3, wpb=3516.055, bsz=146.070, num_updates=45441, lr=0.000148346, gnorm=0.688, clip=0.000, oom=0.000, wall=417, train_wall=13594\n","| epoch 041:    300 / 1131 loss=2.953, nll_loss=1.398, ppl=2.64, wps=11390, ups=3, wpb=3501.797, bsz=147.402, num_updates=45541, lr=0.000148183, gnorm=0.692, clip=0.000, oom=0.000, wall=447, train_wall=13624\n","| epoch 041:    400 / 1131 loss=2.960, nll_loss=1.407, ppl=2.65, wps=11441, ups=3, wpb=3513.100, bsz=146.015, num_updates=45641, lr=0.000148021, gnorm=0.693, clip=0.000, oom=0.000, wall=478, train_wall=13654\n","| epoch 041:    500 / 1131 loss=2.969, nll_loss=1.416, ppl=2.67, wps=11467, ups=3, wpb=3520.152, bsz=144.094, num_updates=45741, lr=0.000147859, gnorm=0.695, clip=0.000, oom=0.000, wall=508, train_wall=13685\n","| epoch 041:    600 / 1131 loss=2.974, nll_loss=1.422, ppl=2.68, wps=11475, ups=3, wpb=3517.977, bsz=144.930, num_updates=45841, lr=0.000147697, gnorm=0.698, clip=0.000, oom=0.000, wall=539, train_wall=13715\n","| epoch 041:    700 / 1131 loss=2.977, nll_loss=1.426, ppl=2.69, wps=11447, ups=3, wpb=3503.223, bsz=144.341, num_updates=45941, lr=0.000147537, gnorm=0.701, clip=0.000, oom=0.000, wall=569, train_wall=13744\n","| epoch 041:    800 / 1131 loss=2.977, nll_loss=1.426, ppl=2.69, wps=11445, ups=3, wpb=3496.377, bsz=145.517, num_updates=46041, lr=0.000147376, gnorm=0.703, clip=0.000, oom=0.000, wall=599, train_wall=13774\n","| epoch 041:    900 / 1131 loss=2.982, nll_loss=1.431, ppl=2.70, wps=11443, ups=3, wpb=3493.572, bsz=143.679, num_updates=46141, lr=0.000147217, gnorm=0.706, clip=0.000, oom=0.000, wall=630, train_wall=13804\n","| epoch 041:   1000 / 1131 loss=2.986, nll_loss=1.436, ppl=2.71, wps=11433, ups=3, wpb=3489.206, bsz=142.009, num_updates=46241, lr=0.000147057, gnorm=0.708, clip=0.000, oom=0.000, wall=660, train_wall=13834\n","| epoch 041:   1100 / 1131 loss=2.990, nll_loss=1.441, ppl=2.71, wps=11448, ups=3, wpb=3491.368, bsz=142.052, num_updates=46341, lr=0.000146898, gnorm=0.709, clip=0.000, oom=0.000, wall=690, train_wall=13864\n","| epoch 041 | loss 2.992 | nll_loss 1.442 | ppl 2.72 | wps 11450 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 46371 | lr 0.000146851 | gnorm 0.709 | clip 0.000 | oom 0.000 | wall 700 | train_wall 13873\n","| epoch 041 | valid on 'valid' subset | loss 3.980 | nll_loss 2.421 | ppl 5.35 | num_updates 46371 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint41.pt (epoch 41 @ 46371 updates) (writing took 4.719651937484741 seconds)\n","| epoch 042:    100 / 1131 loss=2.947, nll_loss=1.389, ppl=2.62, wps=11256, ups=3, wpb=3474.871, bsz=136.634, num_updates=46472, lr=0.000146691, gnorm=0.700, clip=0.000, oom=0.000, wall=740, train_wall=13903\n","| epoch 042:    200 / 1131 loss=2.948, nll_loss=1.391, ppl=2.62, wps=11324, ups=3, wpb=3466.796, bsz=135.363, num_updates=46572, lr=0.000146534, gnorm=0.702, clip=0.000, oom=0.000, wall=770, train_wall=13933\n","| epoch 042:    300 / 1131 loss=2.958, nll_loss=1.402, ppl=2.64, wps=11366, ups=3, wpb=3454.854, bsz=136.133, num_updates=46672, lr=0.000146377, gnorm=0.709, clip=0.000, oom=0.000, wall=800, train_wall=13963\n","| epoch 042:    400 / 1131 loss=2.961, nll_loss=1.405, ppl=2.65, wps=11364, ups=3, wpb=3454.192, bsz=133.845, num_updates=46772, lr=0.00014622, gnorm=0.712, clip=0.000, oom=0.000, wall=831, train_wall=13993\n","| epoch 042:    500 / 1131 loss=2.965, nll_loss=1.410, ppl=2.66, wps=11396, ups=3, wpb=3468.475, bsz=134.180, num_updates=46872, lr=0.000146064, gnorm=0.712, clip=0.000, oom=0.000, wall=861, train_wall=14023\n","| epoch 042:    600 / 1131 loss=2.969, nll_loss=1.414, ppl=2.67, wps=11414, ups=3, wpb=3472.639, bsz=133.617, num_updates=46972, lr=0.000145908, gnorm=0.713, clip=0.000, oom=0.000, wall=892, train_wall=14053\n","| epoch 042:    700 / 1131 loss=2.971, nll_loss=1.417, ppl=2.67, wps=11399, ups=3, wpb=3471.826, bsz=136.331, num_updates=47072, lr=0.000145753, gnorm=0.713, clip=0.000, oom=0.000, wall=922, train_wall=14083\n","| epoch 042:    800 / 1131 loss=2.973, nll_loss=1.419, ppl=2.67, wps=11434, ups=3, wpb=3488.954, bsz=137.788, num_updates=47172, lr=0.000145599, gnorm=0.710, clip=0.000, oom=0.000, wall=953, train_wall=14113\n","| epoch 042:    900 / 1131 loss=2.975, nll_loss=1.422, ppl=2.68, wps=11423, ups=3, wpb=3483.915, bsz=139.747, num_updates=47272, lr=0.000145445, gnorm=0.712, clip=0.000, oom=0.000, wall=984, train_wall=14143\n","| epoch 042:   1000 / 1131 loss=2.977, nll_loss=1.425, ppl=2.68, wps=11428, ups=3, wpb=3483.971, bsz=140.899, num_updates=47372, lr=0.000145291, gnorm=0.712, clip=0.000, oom=0.000, wall=1014, train_wall=14173\n","| epoch 042:   1100 / 1131 loss=2.980, nll_loss=1.429, ppl=2.69, wps=11429, ups=3, wpb=3489.008, bsz=141.238, num_updates=47472, lr=0.000145138, gnorm=0.712, clip=0.000, oom=0.000, wall=1045, train_wall=14204\n","| epoch 042 | loss 2.980 | nll_loss 1.429 | ppl 2.69 | wps 11429 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 47502 | lr 0.000145092 | gnorm 0.712 | clip 0.000 | oom 0.000 | wall 1054 | train_wall 14213\n","| epoch 042 | valid on 'valid' subset | loss 4.005 | nll_loss 2.444 | ppl 5.44 | num_updates 47502 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint42.pt (epoch 42 @ 47502 updates) (writing took 4.727632284164429 seconds)\n","| epoch 043:    100 / 1131 loss=2.954, nll_loss=1.398, ppl=2.63, wps=11373, ups=3, wpb=3535.822, bsz=139.881, num_updates=47603, lr=0.000144938, gnorm=0.697, clip=0.000, oom=0.000, wall=1095, train_wall=14244\n","| epoch 043:    200 / 1131 loss=2.942, nll_loss=1.386, ppl=2.61, wps=11331, ups=3, wpb=3490.214, bsz=153.075, num_updates=47703, lr=0.000144786, gnorm=0.699, clip=0.000, oom=0.000, wall=1126, train_wall=14274\n","| epoch 043:    300 / 1131 loss=2.947, nll_loss=1.391, ppl=2.62, wps=11334, ups=3, wpb=3472.080, bsz=146.179, num_updates=47803, lr=0.000144635, gnorm=0.707, clip=0.000, oom=0.000, wall=1156, train_wall=14304\n","| epoch 043:    400 / 1131 loss=2.949, nll_loss=1.392, ppl=2.62, wps=11351, ups=3, wpb=3480.132, bsz=140.948, num_updates=47903, lr=0.000144484, gnorm=0.708, clip=0.000, oom=0.000, wall=1187, train_wall=14334\n","| epoch 043:    500 / 1131 loss=2.952, nll_loss=1.396, ppl=2.63, wps=11367, ups=3, wpb=3486.631, bsz=139.289, num_updates=48003, lr=0.000144333, gnorm=0.709, clip=0.000, oom=0.000, wall=1218, train_wall=14364\n","| epoch 043:    600 / 1131 loss=2.958, nll_loss=1.402, ppl=2.64, wps=11373, ups=3, wpb=3485.351, bsz=139.754, num_updates=48103, lr=0.000144183, gnorm=0.712, clip=0.000, oom=0.000, wall=1248, train_wall=14394\n","| epoch 043:    700 / 1131 loss=2.960, nll_loss=1.405, ppl=2.65, wps=11377, ups=3, wpb=3479.439, bsz=140.257, num_updates=48203, lr=0.000144033, gnorm=0.713, clip=0.000, oom=0.000, wall=1278, train_wall=14424\n","| epoch 043:    800 / 1131 loss=2.964, nll_loss=1.410, ppl=2.66, wps=11396, ups=3, wpb=3483.483, bsz=141.831, num_updates=48303, lr=0.000143884, gnorm=0.714, clip=0.000, oom=0.000, wall=1309, train_wall=14454\n","| epoch 043:    900 / 1131 loss=2.966, nll_loss=1.412, ppl=2.66, wps=11393, ups=3, wpb=3483.055, bsz=141.042, num_updates=48403, lr=0.000143735, gnorm=0.714, clip=0.000, oom=0.000, wall=1339, train_wall=14484\n","| epoch 043:   1000 / 1131 loss=2.969, nll_loss=1.416, ppl=2.67, wps=11409, ups=3, wpb=3487.145, bsz=140.970, num_updates=48503, lr=0.000143587, gnorm=0.715, clip=0.000, oom=0.000, wall=1370, train_wall=14514\n","| epoch 043:   1100 / 1131 loss=2.971, nll_loss=1.418, ppl=2.67, wps=11423, ups=3, wpb=3493.742, bsz=141.848, num_updates=48603, lr=0.000143439, gnorm=0.714, clip=0.000, oom=0.000, wall=1401, train_wall=14544\n","| epoch 043 | loss 2.970 | nll_loss 1.418 | ppl 2.67 | wps 11417 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 48633 | lr 0.000143395 | gnorm 0.714 | clip 0.000 | oom 0.000 | wall 1410 | train_wall 14553\n","| epoch 043 | valid on 'valid' subset | loss 4.003 | nll_loss 2.440 | ppl 5.43 | num_updates 48633 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint43.pt (epoch 43 @ 48633 updates) (writing took 4.620135068893433 seconds)\n","| epoch 044:    100 / 1131 loss=2.919, nll_loss=1.356, ppl=2.56, wps=11376, ups=3, wpb=3522.752, bsz=134.495, num_updates=48734, lr=0.000143246, gnorm=0.704, clip=0.000, oom=0.000, wall=1451, train_wall=14584\n","| epoch 044:    200 / 1131 loss=2.919, nll_loss=1.356, ppl=2.56, wps=11324, ups=3, wpb=3462.562, bsz=136.199, num_updates=48834, lr=0.0001431, gnorm=0.711, clip=0.000, oom=0.000, wall=1481, train_wall=14614\n","| epoch 044:    300 / 1131 loss=2.923, nll_loss=1.362, ppl=2.57, wps=11257, ups=3, wpb=3452.455, bsz=139.000, num_updates=48934, lr=0.000142953, gnorm=0.712, clip=0.000, oom=0.000, wall=1512, train_wall=14644\n","| epoch 044:    400 / 1131 loss=2.926, nll_loss=1.366, ppl=2.58, wps=11326, ups=3, wpb=3479.928, bsz=149.663, num_updates=49034, lr=0.000142808, gnorm=0.709, clip=0.000, oom=0.000, wall=1542, train_wall=14675\n","| epoch 044:    500 / 1131 loss=2.937, nll_loss=1.378, ppl=2.60, wps=11370, ups=3, wpb=3496.986, bsz=146.329, num_updates=49134, lr=0.000142662, gnorm=0.710, clip=0.000, oom=0.000, wall=1573, train_wall=14705\n","| epoch 044:    600 / 1131 loss=2.941, nll_loss=1.384, ppl=2.61, wps=11397, ups=3, wpb=3507.433, bsz=145.569, num_updates=49234, lr=0.000142517, gnorm=0.709, clip=0.000, oom=0.000, wall=1604, train_wall=14735\n","| epoch 044:    700 / 1131 loss=2.948, nll_loss=1.392, ppl=2.62, wps=11402, ups=3, wpb=3507.509, bsz=145.437, num_updates=49334, lr=0.000142373, gnorm=0.710, clip=0.000, oom=0.000, wall=1635, train_wall=14766\n","| epoch 044:    800 / 1131 loss=2.951, nll_loss=1.395, ppl=2.63, wps=11390, ups=3, wpb=3501.464, bsz=143.589, num_updates=49434, lr=0.000142229, gnorm=0.712, clip=0.000, oom=0.000, wall=1665, train_wall=14796\n","| epoch 044:    900 / 1131 loss=2.951, nll_loss=1.395, ppl=2.63, wps=11371, ups=3, wpb=3491.553, bsz=144.123, num_updates=49534, lr=0.000142085, gnorm=0.713, clip=0.000, oom=0.000, wall=1696, train_wall=14826\n","| epoch 044:   1000 / 1131 loss=2.954, nll_loss=1.398, ppl=2.64, wps=11360, ups=3, wpb=3485.258, bsz=142.600, num_updates=49634, lr=0.000141942, gnorm=0.716, clip=0.000, oom=0.000, wall=1726, train_wall=14856\n","| epoch 044:   1100 / 1131 loss=2.959, nll_loss=1.404, ppl=2.65, wps=11384, ups=3, wpb=3491.745, bsz=141.340, num_updates=49734, lr=0.000141799, gnorm=0.716, clip=0.000, oom=0.000, wall=1757, train_wall=14886\n","| epoch 044 | loss 2.960 | nll_loss 1.405 | ppl 2.65 | wps 11387 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 49764 | lr 0.000141756 | gnorm 0.716 | clip 0.000 | oom 0.000 | wall 1766 | train_wall 14895\n","| epoch 044 | valid on 'valid' subset | loss 3.987 | nll_loss 2.429 | ppl 5.39 | num_updates 49764 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint44.pt (epoch 44 @ 49764 updates) (writing took 4.557683229446411 seconds)\n","| epoch 045:    100 / 1131 loss=2.918, nll_loss=1.357, ppl=2.56, wps=11278, ups=3, wpb=3536.970, bsz=143.129, num_updates=49865, lr=0.000141613, gnorm=0.697, clip=0.000, oom=0.000, wall=1807, train_wall=14926\n","| epoch 045:    200 / 1131 loss=2.911, nll_loss=1.349, ppl=2.55, wps=11361, ups=3, wpb=3538.562, bsz=150.965, num_updates=49965, lr=0.000141471, gnorm=0.698, clip=0.000, oom=0.000, wall=1838, train_wall=14956\n","| epoch 045 | loss 2.911 | nll_loss 1.349 | ppl 2.55 | wps 11366 | ups 3 | wpb 3526.945 | bsz 148.576 | num_updates 50000 | lr 0.000141421 | gnorm 0.700 | clip 0.000 | oom 0.000 | wall 1849 | train_wall 14967\n","| epoch 045 | valid on 'valid' subset | loss 4.006 | nll_loss 2.444 | ppl 5.44 | num_updates 50000 | best_loss 3.92627\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last.pt (epoch 45 @ 50000 updates) (writing took 2.3672890663146973 seconds)\n","| done training in 1854.3 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RTd14wsDKZ4s","colab_type":"code","outputId":"491417aa-b02f-4d12-a432-15d06dc0971d","executionInfo":{"status":"ok","timestamp":1574863082487,"user_tz":-540,"elapsed":2263745,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["!python scripts/average_checkpoints.py --inputs \"{SAVE}\" \\\n","    --num-epoch-checkpoints 10 --output \"{SAVE}/checkpoint_last10_avg.pt\"\n","\n","# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_last10_avg.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt'], num_epoch_checkpoints=10, num_update_checkpoints=None, output='/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last10_avg.pt')\n","averaging checkpoints:  ['/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint44.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint43.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint42.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint41.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint40.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint39.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint38.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint37.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint36.pt', '/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint35.pt']\n","Finished writing averaged checkpoint to /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last10_avg.pt.\n","Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last10_avg.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save_dev4/dynamic_conv_iwslt/checkpoint_last10_avg.pt\n","| Translated 6750 sentences (148440 tokens) in 27.0s (249.85 sentences/s, 5494.48 tokens/s)\n","| Generate test with beam=4: BLEU4 = 34.22, 68.8/42.8/28.7/19.7 (BP=0.953, ratio=0.954, syslen=125100, reflen=131161)\n"],"name":"stdout"}]}]}