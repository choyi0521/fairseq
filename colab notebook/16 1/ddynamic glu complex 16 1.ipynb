{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ddynamic glu complex 16 1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KEO20Jag-R8J","colab_type":"code","outputId":"e401af5d-790f-4203-f570-88bc9aaefc27","executionInfo":{"status":"ok","timestamp":1574441466450,"user_tz":-540,"elapsed":85507,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":508}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# To install fairseq from source and develop locally:\n","!git clone https://github.com/choyi0521/fairseq\n","%cd /content/fairseq\n","!pip install --editable .\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 12164, done.\u001b[K\n","remote: Total 12164 (delta 0), reused 0 (delta 0), pack-reused 12164\u001b[K\n","Receiving objects: 100% (12164/12164), 5.69 MiB | 16.73 MiB/s, done.\n","Resolving deltas: 100% (8955/8955), done.\n","/content/fairseq\n","Obtaining file:///content/fairseq\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.13.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (0.29.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.17.4)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 3.4MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (4.28.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.8.0) (2.19)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.8.0) (3.6.6)\n","Installing collected packages: regex, portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.2 regex-2019.11.1 sacrebleu-1.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43JqPSHkJfQT","colab_type":"code","outputId":"db296814-98fc-45a5-bc93-2b4e5b5e96d6","executionInfo":{"status":"ok","timestamp":1574441469075,"user_tz":-540,"elapsed":88119,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["!git checkout dev3\n","!git pull origin dev3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Branch 'dev3' set up to track remote branch 'dev3' from 'origin'.\n","Switched to a new branch 'dev3'\n","From https://github.com/choyi0521/fairseq\n"," * branch            dev3       -> FETCH_HEAD\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy8_Nx2lAxp9","colab_type":"code","outputId":"830bd866-2f1b-45ad-c5a2-cdab0d219ff2","executionInfo":{"status":"ok","timestamp":1574441752842,"user_tz":-540,"elapsed":371879,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Download and prepare the data\n","%cd /content/fairseq\n","%cd examples/translation/\n","!bash prepare-iwslt14.sh\n","%cd ../..\n","\n","# Preprocess/binarize the data\n","TEXT=\"examples/translation/iwslt14.tokenized.de-en\"\n","!fairseq-preprocess --source-lang de --target-lang en \\\n","    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n","    --destdir data-bin/iwslt14.tokenized.de-en \\\n","    --workers 20"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","/content/fairseq/examples/translation\n","Cloning Moses github repository (for tokenization scripts)...\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 163, done.\u001b[K\n","remote: Counting objects: 100% (163/163), done.\u001b[K\n","remote: Compressing objects: 100% (83/83), done.\u001b[K\n","remote: Total 147458 (delta 101), reused 117 (delta 74), pack-reused 147295\u001b[K\n","Receiving objects: 100% (147458/147458), 129.72 MiB | 19.62 MiB/s, done.\n","Resolving deltas: 100% (113935/113935), done.\n","Cloning Subword NMT repository (for BPE pre-processing)...\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 21, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 530 (delta 9), reused 15 (delta 6), pack-reused 509\u001b[K\n","Receiving objects: 100% (530/530), 224.83 KiB | 4.01 MiB/s, done.\n","Resolving deltas: 100% (315/315), done.\n","Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n","--2019-11-22 16:51:23--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n","Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n","Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19982877 (19M) [application/x-gzip]\n","Saving to: ‘de-en.tgz’\n","\n","de-en.tgz           100%[===================>]  19.06M  5.04MB/s    in 3.8s    \n","\n","2019-11-22 16:51:28 (5.04 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n","\n","Data successfully downloaded.\n","de-en/\n","de-en/IWSLT14.TED.dev2010.de-en.de.xml\n","de-en/IWSLT14.TED.dev2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2010.de-en.de.xml\n","de-en/IWSLT14.TED.tst2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2011.de-en.de.xml\n","de-en/IWSLT14.TED.tst2011.de-en.en.xml\n","de-en/IWSLT14.TED.tst2012.de-en.de.xml\n","de-en/IWSLT14.TED.tst2012.de-en.en.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n","de-en/README\n","de-en/train.en\n","de-en/train.tags.de-en.de\n","de-en/train.tags.de-en.en\n","pre-processing train data...\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n","..........(100000).......\n","Input sentences: 174443  Output sentences:  167522\n","pre-processing valid/test data...\n","orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","creating train, valid, test...\n","learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n","subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","apply_bpe.py to train.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to train.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","/content/fairseq\n","Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', workers=20)\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n","| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GKekFxgwNY9K","colab_type":"code","outputId":"adf10229-593e-4871-bfa1-0a9390de130e","executionInfo":{"status":"ok","timestamp":1574442743255,"user_tz":-540,"elapsed":1362286,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","SAVE=\"/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt\"\n","\n","# Training\n","%cd /content/fairseq\n","!mkdir -p \"{SAVE}\" \n","!CUDA_VISIBLE_DEVICES=0 $(which fairseq-train) data-bin/iwslt14.tokenized.de-en \\\n","    --encoder-conv-type ddynamic --decoder-conv-type ddynamic \\\n","    --clip-norm 0 --optimizer adam --lr 0.0005 \\\n","    --source-lang de --target-lang en --max-tokens 4000 --no-progress-bar \\\n","    --log-interval 100 --min-lr '1e-09' --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --ddp-backend=no_c10d \\\n","    --max-update 50000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n","    --adam-betas '(0.9, 0.98)' --keep-last-epochs 10 \\\n","    -a lightconv_iwslt_de_en --save-dir \"{SAVE}\" \\\n","    --dropout 0.3 --attention-dropout 0.1 --weight-dropout 0.1 \\\n","    --encoder-glu 1 --decoder-glu 1 \\\n","    --encoder-attention-heads 16 --decoder-attention-heads 16 \\\n","    --encoder-attention-proj-heads 1 --decoder-attention-proj-heads 1 \\\n","    --encoder-layers 7 --encoder-kernel-size-list [3,7,15,31,31,31,31] \\\n","    2>&1 | tee \"{SAVE}/train3.log\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='lightconv_iwslt_de_en', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_attention_proj_heads=1, decoder_conv_dim=512, decoder_conv_type='ddynamic', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=True, decoder_input_dim=512, decoder_kernel_size_list=[3, 7, 15, 31, 31, 31], decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_attention_proj_heads=1, encoder_conv_dim=512, encoder_conv_type='ddynamic', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=True, encoder_kernel_size_list=[3, 7, 15, 31, 31, 31, 31], encoder_layers=7, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, input_dropout=0.0, keep_interval_updates=-1, keep_last_epochs=10, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n","| data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n","LightConvModel(\n","  (encoder): LightConvEncoder(\n","    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=1, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=48, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=3, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=112, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=7, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=240, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (4): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (5): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (6): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (decoder): LightConvDecoder(\n","    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=2, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=48, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=6, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=112, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=14, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=240, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n","        (act): GLU(dim=-1)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=16, num_proj_heads=1, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model lightconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 43740160 (num. trained: 43740160)\n","| training on 1 GPUs\n","| max tokens per GPU = 4000 and max sentences per GPU = None\n","| loaded checkpoint /content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last.pt (epoch 43 @ 48633 updates)\n","| loading train data for epoch 43\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n","| data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n","| epoch 044:    100 / 1131 loss=2.941, nll_loss=1.378, ppl=2.60, wps=5087, ups=1, wpb=3522.752, bsz=134.495, num_updates=48734, lr=0.000143246, gnorm=0.749, clip=0.000, oom=0.000, wall=72, train_wall=33106\n","| epoch 044:    200 / 1131 loss=2.939, nll_loss=1.375, ppl=2.59, wps=5061, ups=1, wpb=3462.562, bsz=136.199, num_updates=48834, lr=0.0001431, gnorm=0.757, clip=0.000, oom=0.000, wall=140, train_wall=33173\n","| epoch 044:    300 / 1131 loss=2.942, nll_loss=1.380, ppl=2.60, wps=5049, ups=1, wpb=3452.455, bsz=139.000, num_updates=48934, lr=0.000142953, gnorm=0.760, clip=0.000, oom=0.000, wall=208, train_wall=33241\n","| epoch 044:    400 / 1131 loss=2.946, nll_loss=1.385, ppl=2.61, wps=5079, ups=1, wpb=3479.928, bsz=149.663, num_updates=49034, lr=0.000142808, gnorm=0.756, clip=0.000, oom=0.000, wall=277, train_wall=33309\n","| epoch 044:    500 / 1131 loss=2.956, nll_loss=1.397, ppl=2.63, wps=5093, ups=1, wpb=3496.986, bsz=146.329, num_updates=49134, lr=0.000142662, gnorm=0.758, clip=0.000, oom=0.000, wall=346, train_wall=33378\n","| epoch 044:    600 / 1131 loss=2.961, nll_loss=1.403, ppl=2.64, wps=5103, ups=1, wpb=3507.433, bsz=145.569, num_updates=49234, lr=0.000142517, gnorm=0.757, clip=0.000, oom=0.000, wall=415, train_wall=33446\n","| epoch 044:    700 / 1131 loss=2.968, nll_loss=1.410, ppl=2.66, wps=5108, ups=1, wpb=3507.509, bsz=145.437, num_updates=49334, lr=0.000142373, gnorm=0.759, clip=0.000, oom=0.000, wall=484, train_wall=33514\n","| epoch 044:    800 / 1131 loss=2.971, nll_loss=1.415, ppl=2.67, wps=5102, ups=1, wpb=3501.464, bsz=143.589, num_updates=49434, lr=0.000142229, gnorm=0.762, clip=0.000, oom=0.000, wall=552, train_wall=33582\n","| epoch 044:    900 / 1131 loss=2.972, nll_loss=1.415, ppl=2.67, wps=5089, ups=1, wpb=3491.553, bsz=144.123, num_updates=49534, lr=0.000142085, gnorm=0.763, clip=0.000, oom=0.000, wall=620, train_wall=33650\n","| epoch 044:   1000 / 1131 loss=2.975, nll_loss=1.419, ppl=2.67, wps=5081, ups=1, wpb=3485.258, bsz=142.600, num_updates=49634, lr=0.000141942, gnorm=0.766, clip=0.000, oom=0.000, wall=689, train_wall=33717\n","| epoch 044:   1100 / 1131 loss=2.980, nll_loss=1.424, ppl=2.68, wps=5089, ups=1, wpb=3491.745, bsz=141.340, num_updates=49734, lr=0.000141799, gnorm=0.767, clip=0.000, oom=0.000, wall=758, train_wall=33786\n","| epoch 044 | loss 2.981 | nll_loss 1.426 | ppl 2.69 | wps 5091 | ups 1 | wpb 3491.701 | bsz 141.679 | num_updates 49764 | lr 0.000141756 | gnorm 0.767 | clip 0.000 | oom 0.000 | wall 778 | train_wall 33806\n","| epoch 044 | valid on 'valid' subset | loss 4.048 | nll_loss 2.478 | ppl 5.57 | num_updates 49764 | best_loss 3.96147\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint44.pt (epoch 44 @ 49764 updates) (writing took 5.069028615951538 seconds)\n","| epoch 045:    100 / 1131 loss=2.934, nll_loss=1.371, ppl=2.59, wps=5092, ups=1, wpb=3536.970, bsz=143.129, num_updates=49865, lr=0.000141613, gnorm=0.748, clip=0.000, oom=0.000, wall=867, train_wall=33875\n","| epoch 045:    200 / 1131 loss=2.930, nll_loss=1.367, ppl=2.58, wps=5106, ups=1, wpb=3538.562, bsz=150.965, num_updates=49965, lr=0.000141471, gnorm=0.750, clip=0.000, oom=0.000, wall=936, train_wall=33944\n","| epoch 045 | loss 2.930 | nll_loss 1.367 | ppl 2.58 | wps 5101 | ups 1 | wpb 3526.945 | bsz 148.576 | num_updates 50000 | lr 0.000141421 | gnorm 0.752 | clip 0.000 | oom 0.000 | wall 960 | train_wall 33968\n","| epoch 045 | valid on 'valid' subset | loss 4.061 | nll_loss 2.489 | ppl 5.61 | num_updates 50000 | best_loss 3.96147\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last.pt (epoch 45 @ 50000 updates) (writing took 2.384791612625122 seconds)\n","| done training in 973.7 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RTd14wsDKZ4s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"2e7d4cef-7968-40ca-a8e6-03e9fe0c5e54","executionInfo":{"status":"ok","timestamp":1574442951863,"user_tz":-540,"elapsed":1570891,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}}},"source":["!python scripts/average_checkpoints.py --inputs \"{SAVE}\" \\\n","    --num-epoch-checkpoints 10 --output \"{SAVE}/checkpoint_last10_avg.pt\"\n","\n","# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_last10_avg.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt'], num_epoch_checkpoints=10, num_update_checkpoints=None, output='/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last10_avg.pt')\n","averaging checkpoints:  ['/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint44.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint43.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint42.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint41.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint40.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint39.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint38.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint37.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint36.pt', '/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint35.pt']\n","Finished writing averaged checkpoint to /content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last10_avg.pt.\n","Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last10_avg.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save_dev3/dynamic_conv_iwslt/checkpoint_last10_avg.pt\n","| Translated 6750 sentences (148535 tokens) in 82.3s (82.03 sentences/s, 1805.07 tokens/s)\n","| Generate test with beam=4: BLEU4 = 34.05, 68.6/42.7/28.6/19.5 (BP=0.953, ratio=0.954, syslen=125114, reflen=131161)\n"],"name":"stdout"}]}]}