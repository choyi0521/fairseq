{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dev6 query 4 1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KEO20Jag-R8J","colab_type":"code","outputId":"56028758-f7e1-4eb1-d839-98d9c89a9e69","executionInfo":{"status":"ok","timestamp":1575534462858,"user_tz":-540,"elapsed":70266,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# To install fairseq from source and develop locally:\n","!git clone https://github.com/choyi0521/fairseq\n","%cd /content/fairseq\n","!pip install --editable ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 12181, done.\u001b[K\n","remote: Total 12181 (delta 0), reused 0 (delta 0), pack-reused 12181\u001b[K\n","Receiving objects: 100% (12181/12181), 5.71 MiB | 6.90 MiB/s, done.\n","Resolving deltas: 100% (8965/8965), done.\n","/content/fairseq\n","Obtaining file:///content/fairseq\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.13.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (0.29.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.17.4)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 9.0MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/45/31/1a135b964c169984b27fb2f7a50280fa7f8e6d9d404d8a9e596180487fd1/sacrebleu-1.4.3-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (4.28.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.8.0) (2.19)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.8.0) (3.6.6)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Installing collected packages: regex, portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.2 regex-2019.11.1 sacrebleu-1.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43JqPSHkJfQT","colab_type":"code","outputId":"4ffa5e28-b80e-4860-f39c-7350dcde8a4a","executionInfo":{"status":"ok","timestamp":1575534471514,"user_tz":-540,"elapsed":78912,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!git checkout dev6\n","!git pull origin dev6"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Branch 'dev6' set up to track remote branch 'dev6' from 'origin'.\n","Switched to a new branch 'dev6'\n","From https://github.com/choyi0521/fairseq\n"," * branch            dev6       -> FETCH_HEAD\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy8_Nx2lAxp9","colab_type":"code","outputId":"773cd881-8e93-46c1-911f-e3fae67ec26c","executionInfo":{"status":"ok","timestamp":1575534639949,"user_tz":-540,"elapsed":247341,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Download and prepare the data\n","%cd /content/fairseq\n","%cd examples/translation/\n","!bash prepare-iwslt14.sh\n","%cd ../..\n","\n","# Preprocess/binarize the data\n","TEXT=\"examples/translation/iwslt14.tokenized.de-en\"\n","!fairseq-preprocess --source-lang de --target-lang en \\\n","    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n","    --destdir data-bin/iwslt14.tokenized.de-en \\\n","    --workers 20"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","/content/fairseq/examples/translation\n","Cloning Moses github repository (for tokenization scripts)...\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 169, done.\u001b[K\n","remote: Counting objects: 100% (169/169), done.\u001b[K\n","remote: Compressing objects: 100% (89/89), done.\u001b[K\n","remote: Total 147464 (delta 104), reused 118 (delta 74), pack-reused 147295\u001b[K\n","Receiving objects: 100% (147464/147464), 129.73 MiB | 23.29 MiB/s, done.\n","Resolving deltas: 100% (113938/113938), done.\n","Cloning Subword NMT repository (for BPE pre-processing)...\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 538 (delta 10), reused 21 (delta 7), pack-reused 509\u001b[K\n","Receiving objects: 100% (538/538), 226.98 KiB | 873.00 KiB/s, done.\n","Resolving deltas: 100% (316/316), done.\n","Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n","--2019-12-05 08:28:02--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n","Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n","Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19982877 (19M) [application/x-gzip]\n","Saving to: ‘de-en.tgz’\n","\n","de-en.tgz           100%[===================>]  19.06M  32.9MB/s    in 0.6s    \n","\n","2019-12-05 08:28:02 (32.9 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n","\n","Data successfully downloaded.\n","de-en/\n","de-en/IWSLT14.TED.dev2010.de-en.de.xml\n","de-en/IWSLT14.TED.dev2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2010.de-en.de.xml\n","de-en/IWSLT14.TED.tst2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2011.de-en.de.xml\n","de-en/IWSLT14.TED.tst2011.de-en.en.xml\n","de-en/IWSLT14.TED.tst2012.de-en.de.xml\n","de-en/IWSLT14.TED.tst2012.de-en.en.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n","de-en/README\n","de-en/train.en\n","de-en/train.tags.de-en.de\n","de-en/train.tags.de-en.en\n","pre-processing train data...\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n","..........(100000).......\n","Input sentences: 174443  Output sentences:  167522\n","pre-processing valid/test data...\n","orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","creating train, valid, test...\n","learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n","subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","apply_bpe.py to train.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to train.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","/content/fairseq\n","Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', workers=20)\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n","| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjRkZma01Pej","colab_type":"code","colab":{}},"source":["SAVE=\"/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKekFxgwNY9K","colab_type":"code","outputId":"f8192cc2-df77-4fb1-a7dc-37df271a375a","executionInfo":{"status":"ok","timestamp":1575539335196,"user_tz":-540,"elapsed":1861514,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Training\n","%cd /content/fairseq\n","!mkdir -p \"{SAVE}\" \n","!CUDA_VISIBLE_DEVICES=0 $(which fairseq-train) data-bin/iwslt14.tokenized.de-en \\\n","    --encoder-conv-type ddynamic --decoder-conv-type ddynamic \\\n","    --clip-norm 0 --optimizer adam --lr 0.0005 \\\n","    --source-lang de --target-lang en --max-tokens 4000 --no-progress-bar \\\n","    --log-interval 100 --min-lr '1e-09' --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --ddp-backend=no_c10d \\\n","    --max-update 80000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n","    --adam-betas '(0.9, 0.98)' \\\n","    -a lightconv_iwslt_de_en --save-dir \"{SAVE}\" \\\n","    --dropout 0.3 --attention-dropout 0.1 --weight-dropout 0.1 \\\n","    --encoder-glu 0 --decoder-glu 0 \\\n","    --encoder-gau 0 --decoder-gau 0 \\\n","    --conv-mixed 0 \\\n","    --encoder-conv-dim 512 --decoder-conv-dim 512 \\\n","    --encoder-query-dim 512 --decoder-query-dim 512 \\\n","    --encoder-attention-heads 4 --decoder-attention-heads 4 \\\n","    --encoder-attention-query-heads 1 --decoder-attention-query-heads 1 \\\n","    2>&1 | tee \"{SAVE}/train3.log\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='lightconv_iwslt_de_en', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, conv_mixed=False, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=4, decoder_attention_query_heads=1, decoder_conv_dim=512, decoder_conv_type='ddynamic', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_gau=False, decoder_glu=False, decoder_input_dim=512, decoder_kernel_size_list=[3, 7, 15, 31, 31, 31], decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, decoder_query_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_attention_query_heads=1, encoder_conv_dim=512, encoder_conv_type='ddynamic', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_gau=False, encoder_glu=False, encoder_kernel_size_list=[3, 7, 15, 31, 31, 31, 31], encoder_layers=7, encoder_learned_pos=False, encoder_normalize_before=False, encoder_query_dim=512, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, input_dropout=0.0, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=80000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n","| data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n","LightConvModel(\n","  (encoder): LightConvEncoder(\n","    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=1, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=12, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=3, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=28, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=7, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=60, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (4): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (5): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (6): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (decoder): LightConvDecoder(\n","    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=2, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=12, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=6, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=28, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=14, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=60, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (linear1_query): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=1, conv_mixed=False, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model lightconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 42099712 (num. trained: 42099712)\n","| training on 1 GPUs\n","| max tokens per GPU = 4000 and max sentences per GPU = None\n","| loaded checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last.pt (epoch 60 @ 67860 updates)\n","| loading train data for epoch 60\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n","| data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n","| epoch 061:    100 / 1131 loss=3.213, nll_loss=1.702, ppl=3.25, wps=9856, ups=3, wpb=3570.911, bsz=141.149, num_updates=67961, lr=0.000121303, gnorm=0.876, clip=0.000, oom=0.000, wall=38, train_wall=40502\n","| epoch 061:    200 / 1131 loss=3.208, nll_loss=1.697, ppl=3.24, wps=9745, ups=3, wpb=3510.035, bsz=144.517, num_updates=68061, lr=0.000121213, gnorm=0.886, clip=0.000, oom=0.000, wall=74, train_wall=40538\n","| epoch 061:    300 / 1131 loss=3.217, nll_loss=1.707, ppl=3.27, wps=9737, ups=3, wpb=3515.236, bsz=144.585, num_updates=68161, lr=0.000121125, gnorm=0.889, clip=0.000, oom=0.000, wall=110, train_wall=40574\n","| epoch 061:    400 / 1131 loss=3.219, nll_loss=1.710, ppl=3.27, wps=9679, ups=3, wpb=3505.145, bsz=144.259, num_updates=68261, lr=0.000121036, gnorm=0.891, clip=0.000, oom=0.000, wall=147, train_wall=40610\n","| epoch 061:    500 / 1131 loss=3.228, nll_loss=1.720, ppl=3.29, wps=9648, ups=3, wpb=3503.224, bsz=143.697, num_updates=68361, lr=0.000120947, gnorm=0.894, clip=0.000, oom=0.000, wall=183, train_wall=40646\n","| epoch 061:    600 / 1131 loss=3.235, nll_loss=1.728, ppl=3.31, wps=9591, ups=3, wpb=3495.784, bsz=141.471, num_updates=68461, lr=0.000120859, gnorm=0.898, clip=0.000, oom=0.000, wall=220, train_wall=40683\n","| epoch 061:    700 / 1131 loss=3.238, nll_loss=1.731, ppl=3.32, wps=9547, ups=3, wpb=3492.526, bsz=141.284, num_updates=68561, lr=0.000120771, gnorm=0.900, clip=0.000, oom=0.000, wall=258, train_wall=40720\n","| epoch 061:    800 / 1131 loss=3.242, nll_loss=1.736, ppl=3.33, wps=9506, ups=3, wpb=3481.190, bsz=140.594, num_updates=68661, lr=0.000120683, gnorm=0.905, clip=0.000, oom=0.000, wall=295, train_wall=40756\n","| epoch 061:    900 / 1131 loss=3.245, nll_loss=1.739, ppl=3.34, wps=9485, ups=3, wpb=3482.341, bsz=141.114, num_updates=68761, lr=0.000120595, gnorm=0.905, clip=0.000, oom=0.000, wall=332, train_wall=40793\n","| epoch 061:   1000 / 1131 loss=3.250, nll_loss=1.745, ppl=3.35, wps=9479, ups=3, wpb=3487.720, bsz=141.066, num_updates=68861, lr=0.000120507, gnorm=0.906, clip=0.000, oom=0.000, wall=370, train_wall=40831\n","| epoch 061:   1100 / 1131 loss=3.254, nll_loss=1.750, ppl=3.36, wps=9464, ups=3, wpb=3488.524, bsz=140.751, num_updates=68961, lr=0.00012042, gnorm=0.907, clip=0.000, oom=0.000, wall=407, train_wall=40868\n","| epoch 061 | loss 3.253 | nll_loss 1.749 | ppl 3.36 | wps 9467 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 68991 | lr 0.000120394 | gnorm 0.905 | clip 0.000 | oom 0.000 | wall 419 | train_wall 40879\n","| epoch 061 | valid on 'valid' subset | loss 3.890 | nll_loss 2.324 | ppl 5.01 | num_updates 68991 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint61.pt (epoch 61 @ 68991 updates) (writing took 4.144989490509033 seconds)\n","| epoch 062:    100 / 1131 loss=3.224, nll_loss=1.715, ppl=3.28, wps=9318, ups=3, wpb=3519.792, bsz=146.059, num_updates=69092, lr=0.000120306, gnorm=0.880, clip=0.000, oom=0.000, wall=468, train_wall=40917\n","| epoch 062:    200 / 1131 loss=3.218, nll_loss=1.709, ppl=3.27, wps=9337, ups=3, wpb=3512.478, bsz=148.577, num_updates=69192, lr=0.000120219, gnorm=0.879, clip=0.000, oom=0.000, wall=506, train_wall=40954\n","| epoch 062:    300 / 1131 loss=3.222, nll_loss=1.713, ppl=3.28, wps=9359, ups=3, wpb=3511.910, bsz=144.532, num_updates=69292, lr=0.000120132, gnorm=0.883, clip=0.000, oom=0.000, wall=543, train_wall=40991\n","| epoch 062:    400 / 1131 loss=3.217, nll_loss=1.708, ppl=3.27, wps=9358, ups=3, wpb=3512.127, bsz=147.531, num_updates=69392, lr=0.000120045, gnorm=0.882, clip=0.000, oom=0.000, wall=581, train_wall=41028\n","| epoch 062:    500 / 1131 loss=3.225, nll_loss=1.716, ppl=3.29, wps=9356, ups=3, wpb=3513.000, bsz=145.852, num_updates=69492, lr=0.000119959, gnorm=0.887, clip=0.000, oom=0.000, wall=618, train_wall=41065\n","| epoch 062:    600 / 1131 loss=3.230, nll_loss=1.722, ppl=3.30, wps=9352, ups=3, wpb=3511.301, bsz=143.879, num_updates=69592, lr=0.000119873, gnorm=0.893, clip=0.000, oom=0.000, wall=656, train_wall=41102\n","| epoch 062:    700 / 1131 loss=3.229, nll_loss=1.721, ppl=3.30, wps=9355, ups=3, wpb=3513.053, bsz=144.033, num_updates=69692, lr=0.000119787, gnorm=0.893, clip=0.000, oom=0.000, wall=693, train_wall=41139\n","| epoch 062:    800 / 1131 loss=3.233, nll_loss=1.725, ppl=3.31, wps=9352, ups=3, wpb=3509.383, bsz=142.890, num_updates=69792, lr=0.000119701, gnorm=0.897, clip=0.000, oom=0.000, wall=731, train_wall=41176\n","| epoch 062:    900 / 1131 loss=3.236, nll_loss=1.729, ppl=3.32, wps=9317, ups=3, wpb=3493.018, bsz=141.531, num_updates=69892, lr=0.000119615, gnorm=0.903, clip=0.000, oom=0.000, wall=768, train_wall=41213\n","| epoch 062:   1000 / 1131 loss=3.242, nll_loss=1.736, ppl=3.33, wps=9314, ups=3, wpb=3490.428, bsz=140.930, num_updates=69992, lr=0.00011953, gnorm=0.905, clip=0.000, oom=0.000, wall=805, train_wall=41250\n","| epoch 062:   1100 / 1131 loss=3.244, nll_loss=1.738, ppl=3.34, wps=9321, ups=3, wpb=3495.145, bsz=141.906, num_updates=70092, lr=0.000119444, gnorm=0.905, clip=0.000, oom=0.000, wall=843, train_wall=41287\n","| epoch 062 | loss 3.244 | nll_loss 1.739 | ppl 3.34 | wps 9313 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 70122 | lr 0.000119419 | gnorm 0.906 | clip 0.000 | oom 0.000 | wall 854 | train_wall 41298\n","| epoch 062 | valid on 'valid' subset | loss 3.899 | nll_loss 2.333 | ppl 5.04 | num_updates 70122 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint62.pt (epoch 62 @ 70122 updates) (writing took 4.557981729507446 seconds)\n","| epoch 063:    100 / 1131 loss=3.213, nll_loss=1.699, ppl=3.25, wps=9198, ups=3, wpb=3488.990, bsz=130.851, num_updates=70223, lr=0.000119333, gnorm=0.902, clip=0.000, oom=0.000, wall=904, train_wall=41336\n","| epoch 063:    200 / 1131 loss=3.201, nll_loss=1.687, ppl=3.22, wps=9167, ups=3, wpb=3450.642, bsz=135.478, num_updates=70323, lr=0.000119248, gnorm=0.912, clip=0.000, oom=0.000, wall=942, train_wall=41373\n","| epoch 063:    300 / 1131 loss=3.205, nll_loss=1.692, ppl=3.23, wps=9210, ups=3, wpb=3460.970, bsz=139.372, num_updates=70423, lr=0.000119163, gnorm=0.908, clip=0.000, oom=0.000, wall=979, train_wall=41410\n","| epoch 063:    400 / 1131 loss=3.213, nll_loss=1.702, ppl=3.25, wps=9232, ups=3, wpb=3469.633, bsz=141.065, num_updates=70523, lr=0.000119079, gnorm=0.908, clip=0.000, oom=0.000, wall=1017, train_wall=41447\n","| epoch 063:    500 / 1131 loss=3.214, nll_loss=1.703, ppl=3.26, wps=9262, ups=3, wpb=3479.523, bsz=140.820, num_updates=70623, lr=0.000118995, gnorm=0.907, clip=0.000, oom=0.000, wall=1054, train_wall=41485\n","| epoch 063:    600 / 1131 loss=3.214, nll_loss=1.704, ppl=3.26, wps=9282, ups=3, wpb=3485.504, bsz=142.667, num_updates=70723, lr=0.00011891, gnorm=0.905, clip=0.000, oom=0.000, wall=1092, train_wall=41522\n","| epoch 063:    700 / 1131 loss=3.222, nll_loss=1.713, ppl=3.28, wps=9303, ups=3, wpb=3493.929, bsz=141.534, num_updates=70823, lr=0.000118826, gnorm=0.906, clip=0.000, oom=0.000, wall=1129, train_wall=41559\n","| epoch 063:    800 / 1131 loss=3.226, nll_loss=1.717, ppl=3.29, wps=9311, ups=3, wpb=3492.904, bsz=141.752, num_updates=70923, lr=0.000118743, gnorm=0.907, clip=0.000, oom=0.000, wall=1166, train_wall=41596\n","| epoch 063:    900 / 1131 loss=3.227, nll_loss=1.718, ppl=3.29, wps=9329, ups=3, wpb=3500.344, bsz=143.457, num_updates=71023, lr=0.000118659, gnorm=0.904, clip=0.000, oom=0.000, wall=1204, train_wall=41633\n","| epoch 063:   1000 / 1131 loss=3.230, nll_loss=1.722, ppl=3.30, wps=9318, ups=3, wpb=3493.164, bsz=143.200, num_updates=71123, lr=0.000118576, gnorm=0.907, clip=0.000, oom=0.000, wall=1241, train_wall=41670\n","| epoch 063:   1100 / 1131 loss=3.235, nll_loss=1.728, ppl=3.31, wps=9319, ups=3, wpb=3490.840, bsz=142.328, num_updates=71223, lr=0.000118492, gnorm=0.909, clip=0.000, oom=0.000, wall=1278, train_wall=41706\n","| epoch 063 | loss 3.238 | nll_loss 1.731 | ppl 3.32 | wps 9319 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 71253 | lr 0.000118467 | gnorm 0.911 | clip 0.000 | oom 0.000 | wall 1290 | train_wall 41718\n","| epoch 063 | valid on 'valid' subset | loss 3.892 | nll_loss 2.331 | ppl 5.03 | num_updates 71253 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint63.pt (epoch 63 @ 71253 updates) (writing took 4.338475227355957 seconds)\n","| epoch 064:    100 / 1131 loss=3.201, nll_loss=1.687, ppl=3.22, wps=9156, ups=3, wpb=3482.812, bsz=135.050, num_updates=71354, lr=0.000118383, gnorm=0.907, clip=0.000, oom=0.000, wall=1340, train_wall=41756\n","| epoch 064:    200 / 1131 loss=3.185, nll_loss=1.670, ppl=3.18, wps=9275, ups=3, wpb=3502.592, bsz=144.955, num_updates=71454, lr=0.000118301, gnorm=0.894, clip=0.000, oom=0.000, wall=1377, train_wall=41793\n","| epoch 064:    300 / 1131 loss=3.198, nll_loss=1.685, ppl=3.22, wps=9300, ups=3, wpb=3501.648, bsz=143.548, num_updates=71554, lr=0.000118218, gnorm=0.897, clip=0.000, oom=0.000, wall=1415, train_wall=41830\n","| epoch 064:    400 / 1131 loss=3.201, nll_loss=1.689, ppl=3.22, wps=9299, ups=3, wpb=3499.808, bsz=144.938, num_updates=71654, lr=0.000118135, gnorm=0.898, clip=0.000, oom=0.000, wall=1452, train_wall=41867\n","| epoch 064:    500 / 1131 loss=3.205, nll_loss=1.693, ppl=3.23, wps=9298, ups=3, wpb=3494.251, bsz=143.665, num_updates=71754, lr=0.000118053, gnorm=0.901, clip=0.000, oom=0.000, wall=1490, train_wall=41904\n","| epoch 064:    600 / 1131 loss=3.211, nll_loss=1.701, ppl=3.25, wps=9311, ups=3, wpb=3496.581, bsz=142.908, num_updates=71854, lr=0.000117971, gnorm=0.903, clip=0.000, oom=0.000, wall=1527, train_wall=41941\n","| epoch 064:    700 / 1131 loss=3.216, nll_loss=1.706, ppl=3.26, wps=9322, ups=3, wpb=3496.929, bsz=142.813, num_updates=71954, lr=0.000117889, gnorm=0.906, clip=0.000, oom=0.000, wall=1564, train_wall=41978\n","| epoch 064:    800 / 1131 loss=3.219, nll_loss=1.709, ppl=3.27, wps=9317, ups=3, wpb=3493.660, bsz=142.181, num_updates=72054, lr=0.000117807, gnorm=0.909, clip=0.000, oom=0.000, wall=1602, train_wall=42015\n","| epoch 064:    900 / 1131 loss=3.225, nll_loss=1.716, ppl=3.29, wps=9324, ups=3, wpb=3495.101, bsz=141.042, num_updates=72154, lr=0.000117725, gnorm=0.911, clip=0.000, oom=0.000, wall=1639, train_wall=42052\n","| epoch 064:   1000 / 1131 loss=3.228, nll_loss=1.719, ppl=3.29, wps=9332, ups=3, wpb=3498.380, bsz=141.537, num_updates=72254, lr=0.000117644, gnorm=0.911, clip=0.000, oom=0.000, wall=1677, train_wall=42089\n","| epoch 064:   1100 / 1131 loss=3.230, nll_loss=1.722, ppl=3.30, wps=9322, ups=3, wpb=3495.679, bsz=141.027, num_updates=72354, lr=0.000117562, gnorm=0.913, clip=0.000, oom=0.000, wall=1714, train_wall=42126\n","| epoch 064 | loss 3.230 | nll_loss 1.722 | ppl 3.30 | wps 9312 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 72384 | lr 0.000117538 | gnorm 0.913 | clip 0.000 | oom 0.000 | wall 1725 | train_wall 42137\n","| epoch 064 | valid on 'valid' subset | loss 3.900 | nll_loss 2.332 | ppl 5.03 | num_updates 72384 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint64.pt (epoch 64 @ 72384 updates) (writing took 4.901907920837402 seconds)\n","| epoch 065:    100 / 1131 loss=3.179, nll_loss=1.661, ppl=3.16, wps=8992, ups=3, wpb=3404.287, bsz=129.109, num_updates=72485, lr=0.000117456, gnorm=0.920, clip=0.000, oom=0.000, wall=1776, train_wall=42175\n","| epoch 065:    200 / 1131 loss=3.188, nll_loss=1.672, ppl=3.19, wps=9196, ups=3, wpb=3450.841, bsz=138.547, num_updates=72585, lr=0.000117375, gnorm=0.912, clip=0.000, oom=0.000, wall=1813, train_wall=42212\n","| epoch 065:    300 / 1131 loss=3.193, nll_loss=1.678, ppl=3.20, wps=9200, ups=3, wpb=3446.193, bsz=137.249, num_updates=72685, lr=0.000117294, gnorm=0.918, clip=0.000, oom=0.000, wall=1850, train_wall=42249\n","| epoch 065:    400 / 1131 loss=3.202, nll_loss=1.688, ppl=3.22, wps=9224, ups=3, wpb=3454.269, bsz=135.062, num_updates=72785, lr=0.000117214, gnorm=0.920, clip=0.000, oom=0.000, wall=1888, train_wall=42286\n","| epoch 065:    500 / 1131 loss=3.203, nll_loss=1.690, ppl=3.23, wps=9244, ups=3, wpb=3465.673, bsz=140.423, num_updates=72885, lr=0.000117133, gnorm=0.914, clip=0.000, oom=0.000, wall=1925, train_wall=42323\n","| epoch 065:    600 / 1131 loss=3.208, nll_loss=1.696, ppl=3.24, wps=9263, ups=3, wpb=3474.101, bsz=139.261, num_updates=72985, lr=0.000117053, gnorm=0.915, clip=0.000, oom=0.000, wall=1963, train_wall=42360\n","| epoch 065:    700 / 1131 loss=3.210, nll_loss=1.698, ppl=3.24, wps=9270, ups=3, wpb=3475.592, bsz=140.439, num_updates=73085, lr=0.000116973, gnorm=0.915, clip=0.000, oom=0.000, wall=2000, train_wall=42397\n","| epoch 065:    800 / 1131 loss=3.212, nll_loss=1.700, ppl=3.25, wps=9275, ups=3, wpb=3480.416, bsz=140.643, num_updates=73185, lr=0.000116893, gnorm=0.914, clip=0.000, oom=0.000, wall=2038, train_wall=42434\n","| epoch 065:    900 / 1131 loss=3.215, nll_loss=1.704, ppl=3.26, wps=9285, ups=3, wpb=3481.088, bsz=140.953, num_updates=73285, lr=0.000116813, gnorm=0.914, clip=0.000, oom=0.000, wall=2075, train_wall=42471\n","| epoch 065:   1000 / 1131 loss=3.217, nll_loss=1.707, ppl=3.26, wps=9302, ups=3, wpb=3491.183, bsz=142.848, num_updates=73385, lr=0.000116734, gnorm=0.913, clip=0.000, oom=0.000, wall=2113, train_wall=42509\n","| epoch 065:   1100 / 1131 loss=3.222, nll_loss=1.713, ppl=3.28, wps=9310, ups=3, wpb=3491.810, bsz=141.856, num_updates=73485, lr=0.000116654, gnorm=0.915, clip=0.000, oom=0.000, wall=2150, train_wall=42546\n","| epoch 065 | loss 3.223 | nll_loss 1.714 | ppl 3.28 | wps 9309 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 73515 | lr 0.00011663 | gnorm 0.915 | clip 0.000 | oom 0.000 | wall 2162 | train_wall 42557\n","| epoch 065 | valid on 'valid' subset | loss 3.889 | nll_loss 2.325 | ppl 5.01 | num_updates 73515 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint65.pt (epoch 65 @ 73515 updates) (writing took 4.637454032897949 seconds)\n","| epoch 066:    100 / 1131 loss=3.153, nll_loss=1.635, ppl=3.11, wps=9178, ups=3, wpb=3497.069, bsz=155.802, num_updates=73616, lr=0.00011655, gnorm=0.887, clip=0.000, oom=0.000, wall=2212, train_wall=42595\n","| epoch 066:    200 / 1131 loss=3.164, nll_loss=1.648, ppl=3.13, wps=9280, ups=3, wpb=3515.418, bsz=158.169, num_updates=73716, lr=0.000116471, gnorm=0.882, clip=0.000, oom=0.000, wall=2250, train_wall=42632\n","| epoch 066:    300 / 1131 loss=3.180, nll_loss=1.665, ppl=3.17, wps=9316, ups=3, wpb=3514.578, bsz=153.090, num_updates=73816, lr=0.000116392, gnorm=0.894, clip=0.000, oom=0.000, wall=2287, train_wall=42669\n","| epoch 066:    400 / 1131 loss=3.196, nll_loss=1.683, ppl=3.21, wps=9306, ups=3, wpb=3500.903, bsz=145.955, num_updates=73916, lr=0.000116314, gnorm=0.907, clip=0.000, oom=0.000, wall=2325, train_wall=42706\n","| epoch 066:    500 / 1131 loss=3.201, nll_loss=1.688, ppl=3.22, wps=9314, ups=3, wpb=3507.727, bsz=143.170, num_updates=74016, lr=0.000116235, gnorm=0.910, clip=0.000, oom=0.000, wall=2362, train_wall=42743\n","| epoch 066:    600 / 1131 loss=3.206, nll_loss=1.694, ppl=3.23, wps=9278, ups=3, wpb=3490.569, bsz=140.125, num_updates=74116, lr=0.000116157, gnorm=0.917, clip=0.000, oom=0.000, wall=2400, train_wall=42780\n","| epoch 066:    700 / 1131 loss=3.208, nll_loss=1.696, ppl=3.24, wps=9264, ups=3, wpb=3478.927, bsz=139.000, num_updates=74216, lr=0.000116078, gnorm=0.921, clip=0.000, oom=0.000, wall=2437, train_wall=42817\n","| epoch 066:    800 / 1131 loss=3.211, nll_loss=1.700, ppl=3.25, wps=9281, ups=3, wpb=3486.007, bsz=140.253, num_updates=74316, lr=0.000116, gnorm=0.919, clip=0.000, oom=0.000, wall=2475, train_wall=42854\n","| epoch 066:    900 / 1131 loss=3.212, nll_loss=1.700, ppl=3.25, wps=9287, ups=3, wpb=3486.852, bsz=140.572, num_updates=74416, lr=0.000115922, gnorm=0.918, clip=0.000, oom=0.000, wall=2512, train_wall=42891\n","| epoch 066:   1000 / 1131 loss=3.213, nll_loss=1.703, ppl=3.26, wps=9289, ups=3, wpb=3486.021, bsz=141.777, num_updates=74516, lr=0.000115844, gnorm=0.919, clip=0.000, oom=0.000, wall=2549, train_wall=42928\n","| epoch 066:   1100 / 1131 loss=3.216, nll_loss=1.706, ppl=3.26, wps=9301, ups=3, wpb=3491.772, bsz=141.921, num_updates=74616, lr=0.000115767, gnorm=0.918, clip=0.000, oom=0.000, wall=2587, train_wall=42966\n","| epoch 066 | loss 3.216 | nll_loss 1.706 | ppl 3.26 | wps 9303 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 74646 | lr 0.000115744 | gnorm 0.918 | clip 0.000 | oom 0.000 | wall 2598 | train_wall 42977\n","| epoch 066 | valid on 'valid' subset | loss 3.896 | nll_loss 2.333 | ppl 5.04 | num_updates 74646 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint66.pt (epoch 66 @ 74646 updates) (writing took 4.841075658798218 seconds)\n","| epoch 067:    100 / 1131 loss=3.165, nll_loss=1.648, ppl=3.13, wps=9103, ups=3, wpb=3457.465, bsz=147.485, num_updates=74747, lr=0.000115665, gnorm=0.912, clip=0.000, oom=0.000, wall=2649, train_wall=43015\n","| epoch 067:    200 / 1131 loss=3.180, nll_loss=1.664, ppl=3.17, wps=9284, ups=3, wpb=3498.095, bsz=144.597, num_updates=74847, lr=0.000115588, gnorm=0.904, clip=0.000, oom=0.000, wall=2686, train_wall=43052\n","| epoch 067:    300 / 1131 loss=3.190, nll_loss=1.676, ppl=3.19, wps=9313, ups=3, wpb=3494.645, bsz=145.542, num_updates=74947, lr=0.000115511, gnorm=0.907, clip=0.000, oom=0.000, wall=2723, train_wall=43089\n","| epoch 067:    400 / 1131 loss=3.189, nll_loss=1.674, ppl=3.19, wps=9327, ups=3, wpb=3498.633, bsz=143.082, num_updates=75047, lr=0.000115434, gnorm=0.909, clip=0.000, oom=0.000, wall=2761, train_wall=43126\n","| epoch 067:    500 / 1131 loss=3.193, nll_loss=1.679, ppl=3.20, wps=9313, ups=3, wpb=3485.311, bsz=142.068, num_updates=75147, lr=0.000115357, gnorm=0.914, clip=0.000, oom=0.000, wall=2798, train_wall=43162\n","| epoch 067:    600 / 1131 loss=3.197, nll_loss=1.684, ppl=3.21, wps=9278, ups=3, wpb=3470.980, bsz=141.098, num_updates=75247, lr=0.00011528, gnorm=0.919, clip=0.000, oom=0.000, wall=2835, train_wall=43199\n","| epoch 067:    700 / 1131 loss=3.197, nll_loss=1.683, ppl=3.21, wps=9283, ups=3, wpb=3476.916, bsz=142.459, num_updates=75347, lr=0.000115204, gnorm=0.917, clip=0.000, oom=0.000, wall=2873, train_wall=43237\n","| epoch 067:    800 / 1131 loss=3.199, nll_loss=1.686, ppl=3.22, wps=9294, ups=3, wpb=3483.320, bsz=143.541, num_updates=75447, lr=0.000115127, gnorm=0.916, clip=0.000, oom=0.000, wall=2911, train_wall=43274\n","| epoch 067:    900 / 1131 loss=3.200, nll_loss=1.687, ppl=3.22, wps=9284, ups=3, wpb=3480.265, bsz=143.679, num_updates=75547, lr=0.000115051, gnorm=0.919, clip=0.000, oom=0.000, wall=2948, train_wall=43311\n","| epoch 067:   1000 / 1131 loss=3.204, nll_loss=1.692, ppl=3.23, wps=9290, ups=3, wpb=3482.611, bsz=142.169, num_updates=75647, lr=0.000114975, gnorm=0.920, clip=0.000, oom=0.000, wall=2986, train_wall=43348\n","| epoch 067:   1100 / 1131 loss=3.206, nll_loss=1.695, ppl=3.24, wps=9299, ups=3, wpb=3487.232, bsz=141.827, num_updates=75747, lr=0.000114899, gnorm=0.920, clip=0.000, oom=0.000, wall=3023, train_wall=43385\n","| epoch 067 | loss 3.209 | nll_loss 1.697 | ppl 3.24 | wps 9311 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 75777 | lr 0.000114877 | gnorm 0.919 | clip 0.000 | oom 0.000 | wall 3035 | train_wall 43396\n","| epoch 067 | valid on 'valid' subset | loss 3.894 | nll_loss 2.332 | ppl 5.04 | num_updates 75777 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint67.pt (epoch 67 @ 75777 updates) (writing took 4.633610010147095 seconds)\n","| epoch 068:    100 / 1131 loss=3.151, nll_loss=1.631, ppl=3.10, wps=9197, ups=3, wpb=3507.228, bsz=147.871, num_updates=75878, lr=0.0001148, gnorm=0.901, clip=0.000, oom=0.000, wall=3085, train_wall=43434\n","| epoch 068:    200 / 1131 loss=3.161, nll_loss=1.642, ppl=3.12, wps=9224, ups=3, wpb=3483.338, bsz=149.368, num_updates=75978, lr=0.000114724, gnorm=0.911, clip=0.000, oom=0.000, wall=3122, train_wall=43471\n","| epoch 068:    300 / 1131 loss=3.170, nll_loss=1.653, ppl=3.14, wps=9216, ups=3, wpb=3460.973, bsz=144.980, num_updates=76078, lr=0.000114649, gnorm=0.919, clip=0.000, oom=0.000, wall=3160, train_wall=43508\n","| epoch 068:    400 / 1131 loss=3.176, nll_loss=1.660, ppl=3.16, wps=9253, ups=3, wpb=3471.606, bsz=143.020, num_updates=76178, lr=0.000114574, gnorm=0.919, clip=0.000, oom=0.000, wall=3197, train_wall=43545\n","| epoch 068:    500 / 1131 loss=3.179, nll_loss=1.664, ppl=3.17, wps=9257, ups=3, wpb=3466.351, bsz=144.014, num_updates=76278, lr=0.000114499, gnorm=0.920, clip=0.000, oom=0.000, wall=3234, train_wall=43582\n","| epoch 068:    600 / 1131 loss=3.187, nll_loss=1.672, ppl=3.19, wps=9271, ups=3, wpb=3470.925, bsz=142.374, num_updates=76378, lr=0.000114424, gnorm=0.922, clip=0.000, oom=0.000, wall=3271, train_wall=43619\n","| epoch 068:    700 / 1131 loss=3.187, nll_loss=1.672, ppl=3.19, wps=9272, ups=3, wpb=3472.773, bsz=143.542, num_updates=76478, lr=0.000114349, gnorm=0.922, clip=0.000, oom=0.000, wall=3309, train_wall=43656\n","| epoch 068:    800 / 1131 loss=3.188, nll_loss=1.674, ppl=3.19, wps=9278, ups=3, wpb=3477.159, bsz=144.079, num_updates=76578, lr=0.000114274, gnorm=0.921, clip=0.000, oom=0.000, wall=3347, train_wall=43693\n","| epoch 068:    900 / 1131 loss=3.192, nll_loss=1.679, ppl=3.20, wps=9300, ups=3, wpb=3485.371, bsz=144.168, num_updates=76678, lr=0.0001142, gnorm=0.920, clip=0.000, oom=0.000, wall=3384, train_wall=43730\n","| epoch 068:   1000 / 1131 loss=3.199, nll_loss=1.686, ppl=3.22, wps=9311, ups=3, wpb=3489.949, bsz=141.865, num_updates=76778, lr=0.000114125, gnorm=0.922, clip=0.000, oom=0.000, wall=3422, train_wall=43768\n","| epoch 068:   1100 / 1131 loss=3.201, nll_loss=1.689, ppl=3.22, wps=9314, ups=3, wpb=3492.989, bsz=142.037, num_updates=76878, lr=0.000114051, gnorm=0.922, clip=0.000, oom=0.000, wall=3459, train_wall=43805\n","| epoch 068 | loss 3.202 | nll_loss 1.690 | ppl 3.23 | wps 9311 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 76908 | lr 0.000114029 | gnorm 0.923 | clip 0.000 | oom 0.000 | wall 3471 | train_wall 43816\n","| epoch 068 | valid on 'valid' subset | loss 3.899 | nll_loss 2.332 | ppl 5.03 | num_updates 76908 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint68.pt (epoch 68 @ 76908 updates) (writing took 4.624823331832886 seconds)\n","| epoch 069:    100 / 1131 loss=3.193, nll_loss=1.675, ppl=3.19, wps=9167, ups=3, wpb=3466.881, bsz=113.505, num_updates=77009, lr=0.000113954, gnorm=0.940, clip=0.000, oom=0.000, wall=3521, train_wall=43854\n","| epoch 069:    200 / 1131 loss=3.158, nll_loss=1.637, ppl=3.11, wps=9317, ups=3, wpb=3514.786, bsz=141.095, num_updates=77109, lr=0.00011388, gnorm=0.906, clip=0.000, oom=0.000, wall=3558, train_wall=43891\n","| epoch 069:    300 / 1131 loss=3.164, nll_loss=1.645, ppl=3.13, wps=9324, ups=3, wpb=3505.093, bsz=143.096, num_updates=77209, lr=0.000113806, gnorm=0.909, clip=0.000, oom=0.000, wall=3596, train_wall=43928\n","| epoch 069:    400 / 1131 loss=3.168, nll_loss=1.650, ppl=3.14, wps=9318, ups=3, wpb=3495.387, bsz=139.551, num_updates=77309, lr=0.000113733, gnorm=0.917, clip=0.000, oom=0.000, wall=3633, train_wall=43965\n","| epoch 069:    500 / 1131 loss=3.171, nll_loss=1.653, ppl=3.15, wps=9309, ups=3, wpb=3483.715, bsz=141.589, num_updates=77409, lr=0.000113659, gnorm=0.919, clip=0.000, oom=0.000, wall=3670, train_wall=44002\n","| epoch 069:    600 / 1131 loss=3.176, nll_loss=1.659, ppl=3.16, wps=9323, ups=3, wpb=3489.015, bsz=141.511, num_updates=77509, lr=0.000113586, gnorm=0.918, clip=0.000, oom=0.000, wall=3708, train_wall=44039\n","| epoch 069:    700 / 1131 loss=3.182, nll_loss=1.667, ppl=3.17, wps=9323, ups=3, wpb=3489.437, bsz=141.432, num_updates=77609, lr=0.000113513, gnorm=0.920, clip=0.000, oom=0.000, wall=3745, train_wall=44076\n","| epoch 069:    800 / 1131 loss=3.186, nll_loss=1.670, ppl=3.18, wps=9314, ups=3, wpb=3484.283, bsz=140.654, num_updates=77709, lr=0.00011344, gnorm=0.922, clip=0.000, oom=0.000, wall=3782, train_wall=44113\n","| epoch 069:    900 / 1131 loss=3.188, nll_loss=1.673, ppl=3.19, wps=9320, ups=3, wpb=3489.194, bsz=140.972, num_updates=77809, lr=0.000113367, gnorm=0.923, clip=0.000, oom=0.000, wall=3820, train_wall=44150\n","| epoch 069:   1000 / 1131 loss=3.191, nll_loss=1.677, ppl=3.20, wps=9318, ups=3, wpb=3491.696, bsz=141.082, num_updates=77909, lr=0.000113294, gnorm=0.924, clip=0.000, oom=0.000, wall=3858, train_wall=44187\n","| epoch 069:   1100 / 1131 loss=3.193, nll_loss=1.680, ppl=3.20, wps=9321, ups=3, wpb=3492.420, bsz=142.161, num_updates=78009, lr=0.000113221, gnorm=0.924, clip=0.000, oom=0.000, wall=3895, train_wall=44224\n","| epoch 069 | loss 3.196 | nll_loss 1.682 | ppl 3.21 | wps 9320 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 78039 | lr 0.000113199 | gnorm 0.925 | clip 0.000 | oom 0.000 | wall 3906 | train_wall 44235\n","| epoch 069 | valid on 'valid' subset | loss 3.895 | nll_loss 2.329 | ppl 5.02 | num_updates 78039 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint69.pt (epoch 69 @ 78039 updates) (writing took 5.184067964553833 seconds)\n","| epoch 070:    100 / 1131 loss=3.172, nll_loss=1.653, ppl=3.15, wps=9332, ups=3, wpb=3565.832, bsz=133.376, num_updates=78140, lr=0.000113126, gnorm=0.906, clip=0.000, oom=0.000, wall=3957, train_wall=44273\n","| epoch 070:    200 / 1131 loss=3.153, nll_loss=1.632, ppl=3.10, wps=9320, ups=3, wpb=3527.905, bsz=145.706, num_updates=78240, lr=0.000113054, gnorm=0.905, clip=0.000, oom=0.000, wall=3995, train_wall=44311\n","| epoch 070:    300 / 1131 loss=3.156, nll_loss=1.636, ppl=3.11, wps=9300, ups=3, wpb=3515.645, bsz=144.236, num_updates=78340, lr=0.000112982, gnorm=0.910, clip=0.000, oom=0.000, wall=4033, train_wall=44348\n","| epoch 070:    400 / 1131 loss=3.161, nll_loss=1.641, ppl=3.12, wps=9279, ups=3, wpb=3488.102, bsz=142.002, num_updates=78440, lr=0.00011291, gnorm=0.922, clip=0.000, oom=0.000, wall=4070, train_wall=44384\n","| epoch 070:    500 / 1131 loss=3.168, nll_loss=1.649, ppl=3.14, wps=9292, ups=3, wpb=3490.705, bsz=139.463, num_updates=78540, lr=0.000112838, gnorm=0.924, clip=0.000, oom=0.000, wall=4107, train_wall=44421\n","| epoch 070:    600 / 1131 loss=3.172, nll_loss=1.654, ppl=3.15, wps=9296, ups=3, wpb=3487.532, bsz=138.621, num_updates=78640, lr=0.000112766, gnorm=0.924, clip=0.000, oom=0.000, wall=4144, train_wall=44458\n","| epoch 070:    700 / 1131 loss=3.175, nll_loss=1.658, ppl=3.16, wps=9296, ups=3, wpb=3487.160, bsz=140.609, num_updates=78740, lr=0.000112694, gnorm=0.925, clip=0.000, oom=0.000, wall=4182, train_wall=44495\n","| epoch 070:    800 / 1131 loss=3.179, nll_loss=1.663, ppl=3.17, wps=9304, ups=3, wpb=3488.996, bsz=140.213, num_updates=78840, lr=0.000112623, gnorm=0.927, clip=0.000, oom=0.000, wall=4219, train_wall=44532\n","| epoch 070:    900 / 1131 loss=3.179, nll_loss=1.663, ppl=3.17, wps=9298, ups=3, wpb=3485.284, bsz=140.891, num_updates=78940, lr=0.000112552, gnorm=0.927, clip=0.000, oom=0.000, wall=4257, train_wall=44569\n","| epoch 070:   1000 / 1131 loss=3.183, nll_loss=1.667, ppl=3.18, wps=9301, ups=3, wpb=3483.398, bsz=141.649, num_updates=79040, lr=0.00011248, gnorm=0.928, clip=0.000, oom=0.000, wall=4294, train_wall=44606\n","| epoch 070:   1100 / 1131 loss=3.189, nll_loss=1.674, ppl=3.19, wps=9316, ups=3, wpb=3488.809, bsz=141.194, num_updates=79140, lr=0.000112409, gnorm=0.929, clip=0.000, oom=0.000, wall=4331, train_wall=44643\n","| epoch 070 | loss 3.188 | nll_loss 1.673 | ppl 3.19 | wps 9320 | ups 3 | wpb 3491.701 | bsz 141.679 | num_updates 79170 | lr 0.000112388 | gnorm 0.928 | clip 0.000 | oom 0.000 | wall 4342 | train_wall 44654\n","| epoch 070 | valid on 'valid' subset | loss 3.892 | nll_loss 2.328 | ppl 5.02 | num_updates 79170 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint70.pt (epoch 70 @ 79170 updates) (writing took 4.538226366043091 seconds)\n","| epoch 071:    100 / 1131 loss=3.182, nll_loss=1.664, ppl=3.17, wps=9285, ups=3, wpb=3532.198, bsz=123.802, num_updates=79271, lr=0.000112316, gnorm=0.922, clip=0.000, oom=0.000, wall=4393, train_wall=44692\n","| epoch 071:    200 / 1131 loss=3.176, nll_loss=1.656, ppl=3.15, wps=9298, ups=3, wpb=3508.274, bsz=125.413, num_updates=79371, lr=0.000112246, gnorm=0.926, clip=0.000, oom=0.000, wall=4430, train_wall=44729\n","| epoch 071:    300 / 1131 loss=3.163, nll_loss=1.643, ppl=3.12, wps=9300, ups=3, wpb=3499.458, bsz=133.100, num_updates=79471, lr=0.000112175, gnorm=0.924, clip=0.000, oom=0.000, wall=4468, train_wall=44767\n","| epoch 071:    400 / 1131 loss=3.170, nll_loss=1.651, ppl=3.14, wps=9307, ups=3, wpb=3499.095, bsz=133.364, num_updates=79571, lr=0.000112104, gnorm=0.926, clip=0.000, oom=0.000, wall=4505, train_wall=44804\n","| epoch 071:    500 / 1131 loss=3.165, nll_loss=1.645, ppl=3.13, wps=9296, ups=3, wpb=3493.263, bsz=136.317, num_updates=79671, lr=0.000112034, gnorm=0.925, clip=0.000, oom=0.000, wall=4543, train_wall=44841\n","| epoch 071:    600 / 1131 loss=3.167, nll_loss=1.648, ppl=3.13, wps=9294, ups=3, wpb=3488.458, bsz=136.730, num_updates=79771, lr=0.000111964, gnorm=0.928, clip=0.000, oom=0.000, wall=4580, train_wall=44878\n","| epoch 071:    700 / 1131 loss=3.173, nll_loss=1.655, ppl=3.15, wps=9311, ups=3, wpb=3494.026, bsz=136.775, num_updates=79871, lr=0.000111894, gnorm=0.929, clip=0.000, oom=0.000, wall=4617, train_wall=44915\n","| epoch 071:    800 / 1131 loss=3.175, nll_loss=1.657, ppl=3.15, wps=9304, ups=3, wpb=3489.373, bsz=137.557, num_updates=79971, lr=0.000111824, gnorm=0.929, clip=0.000, oom=0.000, wall=4655, train_wall=44952\n","| epoch 071 | loss 3.175 | nll_loss 1.658 | ppl 3.15 | wps 9301 | ups 3 | wpb 3488.035 | bsz 138.630 | num_updates 80000 | lr 0.000111803 | gnorm 0.929 | clip 0.000 | oom 0.000 | wall 4666 | train_wall 44962\n","| epoch 071 | valid on 'valid' subset | loss 3.906 | nll_loss 2.340 | ppl 5.06 | num_updates 80000 | best_loss 3.88163\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last.pt (epoch 71 @ 80000 updates) (writing took 2.6658811569213867 seconds)\n","| done training in 4674.2 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RTd14wsDKZ4s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"6cd89dd4-b341-4d06-978e-43f6ae24b917","executionInfo":{"status":"ok","timestamp":1575539459365,"user_tz":-540,"elapsed":124175,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}}},"source":["!python scripts/average_checkpoints.py --inputs \"{SAVE}\" \\\n","    --num-epoch-checkpoints 10 --output \"{SAVE}/checkpoint_last10_avg.pt\"\n","\n","# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_last10_avg.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":6,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt'], num_epoch_checkpoints=10, num_update_checkpoints=None, output='/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last10_avg.pt')\n","averaging checkpoints:  ['/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint70.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint69.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint68.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint67.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint66.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint65.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint64.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint63.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint62.pt', '/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint61.pt']\n","Finished writing averaged checkpoint to /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last10_avg.pt.\n","Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last10_avg.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_last10_avg.pt\n","| Translated 6750 sentences (149106 tokens) in 45.8s (147.44 sentences/s, 3256.81 tokens/s)\n","| Generate test with beam=4: BLEU4 = 35.20, 69.3/43.7/29.5/20.4 (BP=0.958, ratio=0.959, syslen=125804, reflen=131161)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YAZfQs7XOTXr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"outputId":"cd1d90df-d8b6-44ae-eb21-1baf50a19734","executionInfo":{"status":"ok","timestamp":1575539557601,"user_tz":-540,"elapsed":98243,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}}},"source":["# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_best.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_best.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save_base/dynamic_conv_iwslt/checkpoint_best.pt\n","| Translated 6750 sentences (148710 tokens) in 45.5s (148.48 sentences/s, 3271.22 tokens/s)\n","| Generate test with beam=4: BLEU4 = 34.83, 68.9/43.3/29.2/20.0 (BP=0.958, ratio=0.959, syslen=125799, reflen=131161)\n"],"name":"stdout"}]}]}