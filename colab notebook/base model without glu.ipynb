{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"base model without glu.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Gy8_Nx2lAxp9","colab_type":"code","outputId":"4736440b-c862-4b1c-d777-b6eec82f6233","executionInfo":{"status":"ok","timestamp":1572854292891,"user_tz":-540,"elapsed":298876,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# To install fairseq from source and develop locally:\n","!git clone https://github.com/pytorch/fairseq\n","%cd /content/fairseq\n","!pip install --editable .\n","\n","# Download and prepare the data\n","%cd /content/fairseq\n","%cd examples/translation/\n","!bash prepare-iwslt14.sh\n","%cd ../..\n","\n","# Preprocess/binarize the data\n","TEXT=\"examples/translation/iwslt14.tokenized.de-en\"\n","!fairseq-preprocess --source-lang de --target-lang en \\\n","    --trainpref $TEXT/train --validpref \"examples/translation/iwslt14.tokenized.de-en/valid\" --testpref \"examples/translation/iwslt14.tokenized.de-en/test\" \\\n","    --destdir data-bin/iwslt14.tokenized.de-en \\\n","    --workers 20"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 11889, done.\u001b[K\n","remote: Total 11889 (delta 0), reused 0 (delta 0), pack-reused 11889\u001b[K\n","Receiving objects: 100% (11889/11889), 5.55 MiB | 4.51 MiB/s, done.\n","Resolving deltas: 100% (8850/8850), done.\n","/content/fairseq\n","Obtaining file:///content/fairseq\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.13.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (0.29.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.17.3)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 6.4MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.3.0+cu100)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (4.28.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.8.0) (2.19)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/60/ec/836a494dbaa72541f691ec4e66f29fdc8db9bcc7f49e1c2d457ba13ced42/portalocker-1.5.1-py2.py3-none-any.whl\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.8.0) (3.6.6)\n","Installing collected packages: regex, portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.1 regex-2019.11.1 sacrebleu-1.4.2\n","/content/fairseq\n","/content/fairseq/examples/translation\n","Cloning Moses github repository (for tokenization scripts)...\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 93, done.\u001b[K\n","remote: Counting objects: 100% (93/93), done.\u001b[K\n","remote: Compressing objects: 100% (56/56), done.\u001b[K\n","remote: Total 147388 (delta 57), reused 55 (delta 36), pack-reused 147295\u001b[K\n","Receiving objects: 100% (147388/147388), 129.71 MiB | 20.16 MiB/s, done.\n","Resolving deltas: 100% (113891/113891), done.\n","Cloning Subword NMT repository (for BPE pre-processing)...\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 10, done.\u001b[K\n","remote: Counting objects: 100% (10/10), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 519 (delta 2), reused 3 (delta 1), pack-reused 509\u001b[K\n","Receiving objects: 100% (519/519), 221.16 KiB | 909.00 KiB/s, done.\n","Resolving deltas: 100% (308/308), done.\n","Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n","--2019-11-04 07:54:32--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n","Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n","Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19982877 (19M) [application/x-gzip]\n","Saving to: ‘de-en.tgz’\n","\n","de-en.tgz           100%[===================>]  19.06M  28.3MB/s    in 0.7s    \n","\n","2019-11-04 07:54:33 (28.3 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n","\n","Data successfully downloaded.\n","de-en/\n","de-en/IWSLT14.TED.dev2010.de-en.de.xml\n","de-en/IWSLT14.TED.dev2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2010.de-en.de.xml\n","de-en/IWSLT14.TED.tst2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2011.de-en.de.xml\n","de-en/IWSLT14.TED.tst2011.de-en.en.xml\n","de-en/IWSLT14.TED.tst2012.de-en.de.xml\n","de-en/IWSLT14.TED.tst2012.de-en.en.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n","de-en/README\n","de-en/train.en\n","de-en/train.tags.de-en.de\n","de-en/train.tags.de-en.en\n","pre-processing train data...\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n","..........(100000).......\n","Input sentences: 174443  Output sentences:  167522\n","pre-processing valid/test data...\n","orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","creating train, valid, test...\n","learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n","subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","apply_bpe.py to train.de...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.de...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.de...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to train.en...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.en...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.en...\n","subword-nmt/apply_bpe.py:341: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:358: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","/content/fairseq\n","Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', workers=20)\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n","| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ShBjnEeTDkXr","colab_type":"code","outputId":"f3c25932-7cef-47f8-fdd6-2a3c09f091ed","executionInfo":{"status":"ok","timestamp":1572884795581,"user_tz":-540,"elapsed":176250,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","SAVE=\"/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt\"\n","\n","# Training\n","%cd /content/fairseq\n","!mkdir -p \"{SAVE}\" \n","!CUDA_VISIBLE_DEVICES=0 $(which fairseq-train) data-bin/iwslt14.tokenized.de-en \\\n","    --clip-norm 0 --optimizer adam --lr 0.0005 \\\n","    --source-lang de --target-lang en --max-tokens 4000 --no-progress-bar \\\n","    --log-interval 100 --min-lr '1e-09' --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --ddp-backend=no_c10d \\\n","    --max-update 50000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n","    --adam-betas '(0.9, 0.98)' --keep-last-epochs 10 \\\n","    -a lightconv_iwslt_de_en --save-dir \"{SAVE}\" \\\n","    --dropout 0.3 --attention-dropout 0.1 --weight-dropout 0.1 \\\n","    --encoder-glu 0 --decoder-glu 0\n","!python scripts/average_checkpoints.py --inputs \"{SAVE}\" \\\n","    --num-epoch-checkpoints 10 --output \"{SAVE}/checkpoint_last10_avg.pt\"\n","\n","# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_last10_avg.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='lightconv_iwslt_de_en', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=4, decoder_conv_dim=512, decoder_conv_type='dynamic', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=False, decoder_input_dim=512, decoder_kernel_size_list=[3, 7, 15, 31, 31, 31], decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_conv_dim=512, encoder_conv_type='dynamic', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=False, encoder_kernel_size_list=[3, 7, 15, 31, 31, 31, 31], encoder_layers=7, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, input_dropout=0.0, keep_interval_updates=-1, keep_last_epochs=10, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n","| data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","LightConvModel(\n","  (encoder): LightConvEncoder(\n","    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=1, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=12, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=3, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=28, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=7, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=60, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (4): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (5): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (6): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (decoder): LightConvDecoder(\n","    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=2, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=12, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=6, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=28, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=14, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=60, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=512, out_features=124, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model lightconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 38685184 (num. trained: 38685184)\n","| training on 1 GPUs\n","| max tokens per GPU = 4000 and max sentences per GPU = None\n","| loaded checkpoint /content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint_last.pt (epoch 45 @ 50000 updates)\n","| loading train data for epoch 45\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n","| data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n","| done training in 0.0 seconds\n","Namespace(checkpoint_upper_bound=None, inputs=['/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt'], num_epoch_checkpoints=10, num_update_checkpoints=None, output='/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint_last10_avg.pt')\n","averaging checkpoints:  ['/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint44.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint43.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint42.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint41.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint40.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint39.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint38.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint37.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint36.pt', '/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint35.pt']\n","Finished writing averaged checkpoint to /content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint_last10_avg.pt.\n","Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint_last10_avg.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save/dynamic_conv_iwslt/checkpoint_last10_avg.pt\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","No module named 'dynamicconv_cuda'\n","| Translated 6750 sentences (148398 tokens) in 72.2s (93.53 sentences/s, 2056.30 tokens/s)\n","| Generate test with beam=4: BLEU4 = 35.19, 69.3/43.8/29.7/20.5 (BP=0.954, ratio=0.955, syslen=125311, reflen=131161)\n"],"name":"stdout"}]}]}