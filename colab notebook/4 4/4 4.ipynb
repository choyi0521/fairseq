{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dev3_non_glu.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KEO20Jag-R8J","colab_type":"code","outputId":"f5d3b87b-a63c-4ff6-c097-2d7ce193c36e","executionInfo":{"status":"ok","timestamp":1574171587759,"user_tz":-540,"elapsed":81476,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# To install fairseq from source and develop locally:\n","!git clone https://github.com/choyi0521/fairseq\n","%cd /content/fairseq\n","!pip install --editable ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 12147 (delta 16), reused 17 (delta 8), pack-reused 12121\u001b[K\n","Receiving objects: 100% (12147/12147), 5.59 MiB | 3.58 MiB/s, done.\n","Resolving deltas: 100% (9050/9050), done.\n","/content/fairseq\n","Obtaining file:///content/fairseq\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.13.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (0.29.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.17.4)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 2.7MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.8.0) (4.28.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.8.0) (2.19)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.8.0) (3.6.6)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Installing collected packages: regex, portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.2 regex-2019.11.1 sacrebleu-1.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43JqPSHkJfQT","colab_type":"code","outputId":"195974a2-e4f9-44c4-f4eb-bd9a5e70c3f6","executionInfo":{"status":"ok","timestamp":1574171593501,"user_tz":-540,"elapsed":87205,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["!git checkout dev3\n","!git pull origin dev3"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Branch 'dev3' set up to track remote branch 'dev3' from 'origin'.\n","Switched to a new branch 'dev3'\n","From https://github.com/choyi0521/fairseq\n"," * branch            dev3       -> FETCH_HEAD\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy8_Nx2lAxp9","colab_type":"code","outputId":"d13b5738-f833-4a0c-c58c-6b61188406f4","executionInfo":{"status":"ok","timestamp":1574171838076,"user_tz":-540,"elapsed":331772,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Download and prepare the data\n","%cd /content/fairseq\n","%cd examples/translation/\n","!bash prepare-iwslt14.sh\n","%cd ../..\n","\n","# Preprocess/binarize the data\n","TEXT=\"examples/translation/iwslt14.tokenized.de-en\"\n","!fairseq-preprocess --source-lang de --target-lang en \\\n","    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n","    --destdir data-bin/iwslt14.tokenized.de-en \\\n","    --workers 20"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","/content/fairseq/examples/translation\n","Cloning Moses github repository (for tokenization scripts)...\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 163, done.\u001b[K\n","remote: Counting objects: 100% (163/163), done.\u001b[K\n","remote: Compressing objects: 100% (83/83), done.\u001b[K\n","remote: Total 147458 (delta 101), reused 117 (delta 74), pack-reused 147295\u001b[K\n","Receiving objects: 100% (147458/147458), 129.72 MiB | 12.04 MiB/s, done.\n","Resolving deltas: 100% (113935/113935), done.\n","Cloning Subword NMT repository (for BPE pre-processing)...\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 21, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 530 (delta 9), reused 15 (delta 6), pack-reused 509\u001b[K\n","Receiving objects: 100% (530/530), 224.83 KiB | 424.00 KiB/s, done.\n","Resolving deltas: 100% (315/315), done.\n","Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n","--2019-11-19 13:53:32--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n","Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n","Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19982877 (19M) [application/x-gzip]\n","Saving to: ‘de-en.tgz’\n","\n","de-en.tgz           100%[===================>]  19.06M  3.46MB/s    in 7.6s    \n","\n","2019-11-19 13:53:41 (2.51 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n","\n","Data successfully downloaded.\n","de-en/\n","de-en/IWSLT14.TED.dev2010.de-en.de.xml\n","de-en/IWSLT14.TED.dev2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2010.de-en.de.xml\n","de-en/IWSLT14.TED.tst2010.de-en.en.xml\n","de-en/IWSLT14.TED.tst2011.de-en.de.xml\n","de-en/IWSLT14.TED.tst2011.de-en.en.xml\n","de-en/IWSLT14.TED.tst2012.de-en.de.xml\n","de-en/IWSLT14.TED.tst2012.de-en.en.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n","de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n","de-en/README\n","de-en/train.en\n","de-en/train.tags.de-en.de\n","de-en/train.tags.de-en.en\n","pre-processing train data...\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n","..........(100000).......\n","Input sentences: 174443  Output sentences:  167522\n","pre-processing valid/test data...\n","orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","\n","creating train, valid, test...\n","learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n","subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","apply_bpe.py to train.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.de...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to train.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to valid.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","apply_bpe.py to test.en...\n","subword-nmt/apply_bpe.py:328: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n","  DeprecationWarning\n","subword-nmt/apply_bpe.py:345: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n","  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n","/content/fairseq\n","Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', workers=20)\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n","| [de] Dictionary: 8847 types\n","| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n","| [en] Dictionary: 6631 types\n","| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n","| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GKekFxgwNY9K","colab_type":"code","outputId":"b3b33a67-7385-4ff8-b2b4-effc3aeb152a","executionInfo":{"status":"ok","timestamp":1574181135173,"user_tz":-540,"elapsed":5687954,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","SAVE=\"/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt\"\n","\n","# Training\n","%cd /content/fairseq\n","!mkdir -p \"{SAVE}\" \n","!CUDA_VISIBLE_DEVICES=0 $(which fairseq-train) data-bin/iwslt14.tokenized.de-en \\\n","    --encoder-conv-type ddynamic --decoder-conv-type ddynamic \\\n","    --clip-norm 0 --optimizer adam --lr 0.0005 \\\n","    --source-lang de --target-lang en --max-tokens 4000 --no-progress-bar \\\n","    --log-interval 100 --min-lr '1e-09' --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --ddp-backend=no_c10d \\\n","    --max-update 50000 --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n","    --adam-betas '(0.9, 0.98)' --keep-last-epochs 10 \\\n","    -a lightconv_iwslt_de_en --save-dir \"{SAVE}\" \\\n","    --dropout 0.3 --attention-dropout 0.1 --weight-dropout 0.1 \\\n","    --encoder-glu 0 --decoder-glu 0 \\\n","    --encoder-attention-heads 4 --decoder-attention-heads 4 \\\n","    --encoder-attention-proj-heads 4 --decoder-attention-proj-heads 4 \\\n","    --encoder-layers 7 --encoder-kernel-size-list [3,7,15,31,31,31,31] \\\n","    2>&1 | tee \"{SAVE}/train2.log\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/fairseq\n","Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='lightconv_iwslt_de_en', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=4, decoder_attention_proj_heads=4, decoder_conv_dim=512, decoder_conv_type='ddynamic', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=False, decoder_input_dim=512, decoder_kernel_size_list=[3, 7, 15, 31, 31, 31], decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_attention_proj_heads=4, encoder_conv_dim=512, encoder_conv_type='ddynamic', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=False, encoder_kernel_size_list=[3, 7, 15, 31, 31, 31, 31], encoder_layers=7, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, input_dropout=0.0, keep_interval_updates=-1, keep_last_epochs=10, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n","| loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n","| data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n","LightConvModel(\n","  (encoder): LightConvEncoder(\n","    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=1, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=48, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=3, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=112, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=7, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=240, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (4): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (5): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (6): LightConvEncoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=15, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (layer_norms): ModuleList(\n","          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (decoder): LightConvDecoder(\n","    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=3, padding_l=2, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=48, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=7, padding_l=6, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=112, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=15, padding_l=14, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=240, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): LightConvDecoderLayer(\n","        dropout=0.3, relu_dropout=0.0, input_dropout=0.0, normalize_before=False\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (conv): DDynamicConv1dTBC(\n","          512, kernel_size=31, padding_l=30, num_heads=4, num_proj_heads=4, weight_softmax=True, conv_bias=False, renorm_padding=False, in_proj=False, weight_dropout=0.1\n","          (weight_linear): Linear(in_features=128, out_features=496, bias=False)\n","        )\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (conv_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model lightconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 38685184 (num. trained: 38685184)\n","| training on 1 GPUs\n","| max tokens per GPU = 4000 and max sentences per GPU = None\n","| loaded checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last.pt (epoch 32 @ 36192 updates)\n","| loading train data for epoch 32\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n","| loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n","| data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n","| epoch 033:    100 / 1131 loss=3.134, nll_loss=1.608, ppl=3.05, wps=5348, ups=2, wpb=3508.277, bsz=133.624, num_updates=36293, lr=0.000165993, gnorm=0.708, clip=0.000, oom=0.000, wall=68, train_wall=22844\n","| epoch 033:    200 / 1131 loss=3.134, nll_loss=1.610, ppl=3.05, wps=5357, ups=2, wpb=3511.149, bsz=141.174, num_updates=36393, lr=0.000165764, gnorm=0.711, clip=0.000, oom=0.000, wall=134, train_wall=22909\n","| epoch 033:    300 / 1131 loss=3.137, nll_loss=1.613, ppl=3.06, wps=5347, ups=2, wpb=3500.568, bsz=139.349, num_updates=36493, lr=0.000165537, gnorm=0.715, clip=0.000, oom=0.000, wall=199, train_wall=22974\n","| epoch 033:    400 / 1131 loss=3.138, nll_loss=1.614, ppl=3.06, wps=5343, ups=2, wpb=3503.491, bsz=139.052, num_updates=36593, lr=0.000165311, gnorm=0.716, clip=0.000, oom=0.000, wall=265, train_wall=23039\n","| epoch 033:    500 / 1131 loss=3.139, nll_loss=1.615, ppl=3.06, wps=5320, ups=2, wpb=3484.683, bsz=138.890, num_updates=36693, lr=0.000165085, gnorm=0.720, clip=0.000, oom=0.000, wall=330, train_wall=23104\n","| epoch 033:    600 / 1131 loss=3.148, nll_loss=1.625, ppl=3.08, wps=5326, ups=2, wpb=3488.664, bsz=138.037, num_updates=36793, lr=0.000164861, gnorm=0.723, clip=0.000, oom=0.000, wall=395, train_wall=23169\n","| epoch 033:    700 / 1131 loss=3.148, nll_loss=1.625, ppl=3.08, wps=5333, ups=2, wpb=3495.133, bsz=140.929, num_updates=36893, lr=0.000164637, gnorm=0.723, clip=0.000, oom=0.000, wall=461, train_wall=23234\n","| epoch 033:    800 / 1131 loss=3.149, nll_loss=1.627, ppl=3.09, wps=5332, ups=2, wpb=3490.804, bsz=141.871, num_updates=36993, lr=0.000164415, gnorm=0.724, clip=0.000, oom=0.000, wall=526, train_wall=23298\n","| epoch 033:    900 / 1131 loss=3.154, nll_loss=1.633, ppl=3.10, wps=5334, ups=2, wpb=3492.580, bsz=140.501, num_updates=37093, lr=0.000164193, gnorm=0.725, clip=0.000, oom=0.000, wall=592, train_wall=23363\n","| epoch 033:   1000 / 1131 loss=3.157, nll_loss=1.636, ppl=3.11, wps=5332, ups=2, wpb=3491.672, bsz=141.234, num_updates=37193, lr=0.000163972, gnorm=0.726, clip=0.000, oom=0.000, wall=657, train_wall=23428\n","| epoch 033:   1100 / 1131 loss=3.160, nll_loss=1.640, ppl=3.12, wps=5336, ups=2, wpb=3495.067, bsz=142.030, num_updates=37293, lr=0.000163752, gnorm=0.726, clip=0.000, oom=0.000, wall=723, train_wall=23494\n","| epoch 033 | loss 3.160 | nll_loss 1.640 | ppl 3.12 | wps 5332 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 37323 | lr 0.000163686 | gnorm 0.726 | clip 0.000 | oom 0.000 | wall 742 | train_wall 23513\n","| epoch 033 | valid on 'valid' subset | loss 3.923 | nll_loss 2.352 | ppl 5.11 | num_updates 37323 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint33.pt (epoch 33 @ 37323 updates) (writing took 3.926995038986206 seconds)\n","| epoch 034:    100 / 1131 loss=3.095, nll_loss=1.564, ppl=2.96, wps=5257, ups=2, wpb=3461.574, bsz=149.782, num_updates=37424, lr=0.000163465, gnorm=0.715, clip=0.000, oom=0.000, wall=826, train_wall=23579\n","| epoch 034:    200 / 1131 loss=3.098, nll_loss=1.568, ppl=2.97, wps=5280, ups=2, wpb=3457.423, bsz=148.139, num_updates=37524, lr=0.000163247, gnorm=0.715, clip=0.000, oom=0.000, wall=891, train_wall=23643\n","| epoch 034:    300 / 1131 loss=3.106, nll_loss=1.577, ppl=2.98, wps=5316, ups=2, wpb=3482.488, bsz=149.183, num_updates=37624, lr=0.00016303, gnorm=0.715, clip=0.000, oom=0.000, wall=956, train_wall=23708\n","| epoch 034:    400 / 1131 loss=3.120, nll_loss=1.593, ppl=3.02, wps=5321, ups=2, wpb=3489.454, bsz=145.736, num_updates=37724, lr=0.000162814, gnorm=0.718, clip=0.000, oom=0.000, wall=1022, train_wall=23774\n","| epoch 034:    500 / 1131 loss=3.130, nll_loss=1.605, ppl=3.04, wps=5333, ups=2, wpb=3491.655, bsz=141.589, num_updates=37824, lr=0.000162598, gnorm=0.724, clip=0.000, oom=0.000, wall=1087, train_wall=23838\n","| epoch 034:    600 / 1131 loss=3.138, nll_loss=1.613, ppl=3.06, wps=5338, ups=2, wpb=3499.434, bsz=141.311, num_updates=37924, lr=0.000162384, gnorm=0.725, clip=0.000, oom=0.000, wall=1153, train_wall=23904\n","| epoch 034:    700 / 1131 loss=3.139, nll_loss=1.615, ppl=3.06, wps=5349, ups=2, wpb=3509.392, bsz=143.030, num_updates=38024, lr=0.00016217, gnorm=0.724, clip=0.000, oom=0.000, wall=1219, train_wall=23969\n","| epoch 034:    800 / 1131 loss=3.139, nll_loss=1.615, ppl=3.06, wps=5346, ups=2, wpb=3504.213, bsz=144.120, num_updates=38124, lr=0.000161957, gnorm=0.725, clip=0.000, oom=0.000, wall=1284, train_wall=24034\n","| epoch 034:    900 / 1131 loss=3.139, nll_loss=1.616, ppl=3.07, wps=5336, ups=2, wpb=3494.212, bsz=145.137, num_updates=38224, lr=0.000161745, gnorm=0.726, clip=0.000, oom=0.000, wall=1349, train_wall=24098\n","| epoch 034:   1000 / 1131 loss=3.143, nll_loss=1.620, ppl=3.07, wps=5327, ups=2, wpb=3488.118, bsz=143.288, num_updates=38324, lr=0.000161534, gnorm=0.728, clip=0.000, oom=0.000, wall=1415, train_wall=24163\n","| epoch 034:   1100 / 1131 loss=3.147, nll_loss=1.625, ppl=3.08, wps=5330, ups=2, wpb=3491.649, bsz=142.328, num_updates=38424, lr=0.000161324, gnorm=0.729, clip=0.000, oom=0.000, wall=1481, train_wall=24228\n","| epoch 034 | loss 3.148 | nll_loss 1.625 | ppl 3.09 | wps 5329 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 38454 | lr 0.000161261 | gnorm 0.729 | clip 0.000 | oom 0.000 | wall 1500 | train_wall 24248\n","| epoch 034 | valid on 'valid' subset | loss 3.916 | nll_loss 2.346 | ppl 5.08 | num_updates 38454 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint34.pt (epoch 34 @ 38454 updates) (writing took 4.081621408462524 seconds)\n","| epoch 035:    100 / 1131 loss=3.065, nll_loss=1.532, ppl=2.89, wps=5280, ups=2, wpb=3473.703, bsz=154.851, num_updates=38555, lr=0.00016105, gnorm=0.710, clip=0.000, oom=0.000, wall=1584, train_wall=24314\n","| epoch 035:    200 / 1131 loss=3.092, nll_loss=1.561, ppl=2.95, wps=5282, ups=2, wpb=3469.592, bsz=144.358, num_updates=38655, lr=0.000160841, gnorm=0.725, clip=0.000, oom=0.000, wall=1649, train_wall=24379\n","| epoch 035:    300 / 1131 loss=3.103, nll_loss=1.573, ppl=2.97, wps=5295, ups=2, wpb=3473.967, bsz=141.342, num_updates=38755, lr=0.000160634, gnorm=0.731, clip=0.000, oom=0.000, wall=1715, train_wall=24444\n","| epoch 035:    400 / 1131 loss=3.103, nll_loss=1.574, ppl=2.98, wps=5306, ups=2, wpb=3479.571, bsz=144.080, num_updates=38855, lr=0.000160427, gnorm=0.729, clip=0.000, oom=0.000, wall=1780, train_wall=24509\n","| epoch 035:    500 / 1131 loss=3.113, nll_loss=1.584, ppl=3.00, wps=5314, ups=2, wpb=3483.000, bsz=140.343, num_updates=38955, lr=0.000160221, gnorm=0.731, clip=0.000, oom=0.000, wall=1845, train_wall=24573\n","| epoch 035:    600 / 1131 loss=3.116, nll_loss=1.588, ppl=3.01, wps=5312, ups=2, wpb=3474.982, bsz=140.326, num_updates=39055, lr=0.000160015, gnorm=0.734, clip=0.000, oom=0.000, wall=1910, train_wall=24638\n","| epoch 035:    700 / 1131 loss=3.121, nll_loss=1.594, ppl=3.02, wps=5327, ups=2, wpb=3486.021, bsz=141.946, num_updates=39155, lr=0.000159811, gnorm=0.734, clip=0.000, oom=0.000, wall=1976, train_wall=24703\n","| epoch 035:    800 / 1131 loss=3.123, nll_loss=1.596, ppl=3.02, wps=5330, ups=2, wpb=3487.849, bsz=144.350, num_updates=39255, lr=0.000159607, gnorm=0.732, clip=0.000, oom=0.000, wall=2041, train_wall=24767\n","| epoch 035:    900 / 1131 loss=3.125, nll_loss=1.600, ppl=3.03, wps=5329, ups=2, wpb=3489.051, bsz=143.521, num_updates=39355, lr=0.000159404, gnorm=0.733, clip=0.000, oom=0.000, wall=2107, train_wall=24833\n","| epoch 035:   1000 / 1131 loss=3.130, nll_loss=1.604, ppl=3.04, wps=5334, ups=2, wpb=3494.074, bsz=142.593, num_updates=39455, lr=0.000159202, gnorm=0.734, clip=0.000, oom=0.000, wall=2173, train_wall=24898\n","| epoch 035:   1100 / 1131 loss=3.134, nll_loss=1.609, ppl=3.05, wps=5330, ups=2, wpb=3491.269, bsz=141.797, num_updates=39555, lr=0.000159001, gnorm=0.735, clip=0.000, oom=0.000, wall=2238, train_wall=24963\n","| epoch 035 | loss 3.135 | nll_loss 1.610 | ppl 3.05 | wps 5331 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 39585 | lr 0.000158941 | gnorm 0.736 | clip 0.000 | oom 0.000 | wall 2258 | train_wall 24982\n","| epoch 035 | valid on 'valid' subset | loss 3.910 | nll_loss 2.342 | ppl 5.07 | num_updates 39585 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint35.pt (epoch 35 @ 39585 updates) (writing took 4.583448648452759 seconds)\n","| epoch 036:    100 / 1131 loss=3.101, nll_loss=1.569, ppl=2.97, wps=5355, ups=1, wpb=3560.059, bsz=134.653, num_updates=39686, lr=0.000158738, gnorm=0.709, clip=0.000, oom=0.000, wall=2343, train_wall=25049\n","| epoch 036:    200 / 1131 loss=3.096, nll_loss=1.564, ppl=2.96, wps=5309, ups=2, wpb=3504.796, bsz=139.383, num_updates=39786, lr=0.000158539, gnorm=0.721, clip=0.000, oom=0.000, wall=2408, train_wall=25114\n","| epoch 036:    300 / 1131 loss=3.093, nll_loss=1.562, ppl=2.95, wps=5317, ups=2, wpb=3500.502, bsz=145.462, num_updates=39886, lr=0.00015834, gnorm=0.723, clip=0.000, oom=0.000, wall=2474, train_wall=25179\n","| epoch 036:    400 / 1131 loss=3.094, nll_loss=1.563, ppl=2.95, wps=5302, ups=2, wpb=3488.511, bsz=147.012, num_updates=39986, lr=0.000158142, gnorm=0.725, clip=0.000, oom=0.000, wall=2539, train_wall=25244\n","| epoch 036:    500 / 1131 loss=3.102, nll_loss=1.572, ppl=2.97, wps=5310, ups=2, wpb=3487.467, bsz=143.856, num_updates=40086, lr=0.000157944, gnorm=0.730, clip=0.000, oom=0.000, wall=2604, train_wall=25309\n","| epoch 036:    600 / 1131 loss=3.104, nll_loss=1.574, ppl=2.98, wps=5317, ups=2, wpb=3489.681, bsz=143.293, num_updates=40186, lr=0.000157748, gnorm=0.731, clip=0.000, oom=0.000, wall=2670, train_wall=25374\n","| epoch 036:    700 / 1131 loss=3.107, nll_loss=1.577, ppl=2.98, wps=5322, ups=2, wpb=3491.753, bsz=142.937, num_updates=40286, lr=0.000157552, gnorm=0.732, clip=0.000, oom=0.000, wall=2735, train_wall=25439\n","| epoch 036:    800 / 1131 loss=3.110, nll_loss=1.581, ppl=2.99, wps=5319, ups=2, wpb=3488.675, bsz=142.311, num_updates=40386, lr=0.000157356, gnorm=0.734, clip=0.000, oom=0.000, wall=2801, train_wall=25503\n","| epoch 036:    900 / 1131 loss=3.112, nll_loss=1.584, ppl=3.00, wps=5321, ups=2, wpb=3491.061, bsz=143.368, num_updates=40486, lr=0.000157162, gnorm=0.734, clip=0.000, oom=0.000, wall=2867, train_wall=25569\n","| epoch 036:   1000 / 1131 loss=3.117, nll_loss=1.589, ppl=3.01, wps=5324, ups=2, wpb=3490.861, bsz=142.041, num_updates=40586, lr=0.000156968, gnorm=0.736, clip=0.000, oom=0.000, wall=2932, train_wall=25633\n","| epoch 036:   1100 / 1131 loss=3.119, nll_loss=1.591, ppl=3.01, wps=5322, ups=2, wpb=3490.192, bsz=142.342, num_updates=40686, lr=0.000156775, gnorm=0.736, clip=0.000, oom=0.000, wall=2997, train_wall=25698\n","| epoch 036 | loss 3.121 | nll_loss 1.594 | ppl 3.02 | wps 5324 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 40716 | lr 0.000156717 | gnorm 0.737 | clip 0.000 | oom 0.000 | wall 3017 | train_wall 25718\n","| epoch 036 | valid on 'valid' subset | loss 3.901 | nll_loss 2.337 | ppl 5.05 | num_updates 40716 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint36.pt (epoch 36 @ 40716 updates) (writing took 4.516024827957153 seconds)\n","| epoch 037:    100 / 1131 loss=3.078, nll_loss=1.543, ppl=2.91, wps=5264, ups=2, wpb=3480.446, bsz=134.099, num_updates=40817, lr=0.000156523, gnorm=0.729, clip=0.000, oom=0.000, wall=3101, train_wall=25784\n","| epoch 037:    200 / 1131 loss=3.070, nll_loss=1.536, ppl=2.90, wps=5296, ups=2, wpb=3491.015, bsz=149.413, num_updates=40917, lr=0.000156332, gnorm=0.724, clip=0.000, oom=0.000, wall=3167, train_wall=25849\n","| epoch 037:    300 / 1131 loss=3.074, nll_loss=1.540, ppl=2.91, wps=5309, ups=2, wpb=3495.017, bsz=145.993, num_updates=41017, lr=0.000156141, gnorm=0.726, clip=0.000, oom=0.000, wall=3233, train_wall=25914\n","| epoch 037:    400 / 1131 loss=3.085, nll_loss=1.552, ppl=2.93, wps=5318, ups=2, wpb=3497.464, bsz=144.918, num_updates=41117, lr=0.000155951, gnorm=0.731, clip=0.000, oom=0.000, wall=3298, train_wall=25979\n","| epoch 037:    500 / 1131 loss=3.089, nll_loss=1.557, ppl=2.94, wps=5317, ups=2, wpb=3491.341, bsz=143.521, num_updates=41217, lr=0.000155762, gnorm=0.733, clip=0.000, oom=0.000, wall=3363, train_wall=26044\n","| epoch 037:    600 / 1131 loss=3.093, nll_loss=1.562, ppl=2.95, wps=5325, ups=2, wpb=3497.136, bsz=142.349, num_updates=41317, lr=0.000155573, gnorm=0.733, clip=0.000, oom=0.000, wall=3429, train_wall=26109\n","| epoch 037:    700 / 1131 loss=3.095, nll_loss=1.563, ppl=2.96, wps=5319, ups=2, wpb=3486.210, bsz=141.877, num_updates=41417, lr=0.000155386, gnorm=0.736, clip=0.000, oom=0.000, wall=3494, train_wall=26173\n","| epoch 037:    800 / 1131 loss=3.098, nll_loss=1.568, ppl=2.96, wps=5326, ups=2, wpb=3492.301, bsz=141.913, num_updates=41517, lr=0.000155198, gnorm=0.736, clip=0.000, oom=0.000, wall=3560, train_wall=26239\n","| epoch 037:    900 / 1131 loss=3.102, nll_loss=1.572, ppl=2.97, wps=5324, ups=2, wpb=3490.897, bsz=141.504, num_updates=41617, lr=0.000155012, gnorm=0.737, clip=0.000, oom=0.000, wall=3625, train_wall=26304\n","| epoch 037:   1000 / 1131 loss=3.106, nll_loss=1.577, ppl=2.98, wps=5321, ups=2, wpb=3485.668, bsz=140.690, num_updates=41717, lr=0.000154826, gnorm=0.739, clip=0.000, oom=0.000, wall=3690, train_wall=26368\n","| epoch 037:   1100 / 1131 loss=3.108, nll_loss=1.579, ppl=2.99, wps=5323, ups=2, wpb=3487.234, bsz=141.768, num_updates=41817, lr=0.000154641, gnorm=0.739, clip=0.000, oom=0.000, wall=3756, train_wall=26433\n","| epoch 037 | loss 3.110 | nll_loss 1.581 | ppl 2.99 | wps 5328 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 41847 | lr 0.000154585 | gnorm 0.740 | clip 0.000 | oom 0.000 | wall 3776 | train_wall 26453\n","| epoch 037 | valid on 'valid' subset | loss 3.904 | nll_loss 2.338 | ppl 5.06 | num_updates 41847 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint37.pt (epoch 37 @ 41847 updates) (writing took 4.485818386077881 seconds)\n","| epoch 038:    100 / 1131 loss=3.029, nll_loss=1.488, ppl=2.81, wps=5229, ups=2, wpb=3460.089, bsz=148.040, num_updates=41948, lr=0.000154399, gnorm=0.721, clip=0.000, oom=0.000, wall=3860, train_wall=26519\n","| epoch 038:    200 / 1131 loss=3.041, nll_loss=1.502, ppl=2.83, wps=5287, ups=2, wpb=3476.303, bsz=148.617, num_updates=42048, lr=0.000154215, gnorm=0.724, clip=0.000, oom=0.000, wall=3925, train_wall=26584\n","| epoch 038:    300 / 1131 loss=3.048, nll_loss=1.511, ppl=2.85, wps=5320, ups=2, wpb=3503.628, bsz=149.130, num_updates=42148, lr=0.000154032, gnorm=0.722, clip=0.000, oom=0.000, wall=3991, train_wall=26649\n","| epoch 038:    400 / 1131 loss=3.062, nll_loss=1.526, ppl=2.88, wps=5317, ups=2, wpb=3499.993, bsz=145.776, num_updates=42248, lr=0.00015385, gnorm=0.729, clip=0.000, oom=0.000, wall=4057, train_wall=26715\n","| epoch 038:    500 / 1131 loss=3.067, nll_loss=1.532, ppl=2.89, wps=5325, ups=2, wpb=3504.453, bsz=144.719, num_updates=42348, lr=0.000153668, gnorm=0.730, clip=0.000, oom=0.000, wall=4123, train_wall=26780\n","| epoch 038:    600 / 1131 loss=3.077, nll_loss=1.543, ppl=2.91, wps=5321, ups=2, wpb=3491.542, bsz=143.973, num_updates=42448, lr=0.000153487, gnorm=0.735, clip=0.000, oom=0.000, wall=4187, train_wall=26844\n","| epoch 038:    700 / 1131 loss=3.081, nll_loss=1.548, ppl=2.92, wps=5325, ups=2, wpb=3491.650, bsz=142.265, num_updates=42548, lr=0.000153306, gnorm=0.737, clip=0.000, oom=0.000, wall=4253, train_wall=26909\n","| epoch 038:    800 / 1131 loss=3.082, nll_loss=1.548, ppl=2.93, wps=5331, ups=2, wpb=3499.122, bsz=142.702, num_updates=42648, lr=0.000153127, gnorm=0.736, clip=0.000, oom=0.000, wall=4319, train_wall=26974\n","| epoch 038:    900 / 1131 loss=3.085, nll_loss=1.552, ppl=2.93, wps=5334, ups=2, wpb=3500.245, bsz=143.387, num_updates=42748, lr=0.000152947, gnorm=0.736, clip=0.000, oom=0.000, wall=4384, train_wall=27039\n","| epoch 038:   1000 / 1131 loss=3.089, nll_loss=1.557, ppl=2.94, wps=5326, ups=2, wpb=3491.694, bsz=142.338, num_updates=42848, lr=0.000152769, gnorm=0.739, clip=0.000, oom=0.000, wall=4449, train_wall=27104\n","| epoch 038:   1100 / 1131 loss=3.095, nll_loss=1.564, ppl=2.96, wps=5325, ups=2, wpb=3491.828, bsz=141.797, num_updates=42948, lr=0.000152591, gnorm=0.741, clip=0.000, oom=0.000, wall=4515, train_wall=27169\n","| epoch 038 | loss 3.097 | nll_loss 1.567 | ppl 2.96 | wps 5326 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 42978 | lr 0.000152538 | gnorm 0.742 | clip 0.000 | oom 0.000 | wall 4534 | train_wall 27188\n","| epoch 038 | valid on 'valid' subset | loss 3.928 | nll_loss 2.360 | ppl 5.13 | num_updates 42978 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint38.pt (epoch 38 @ 42978 updates) (writing took 4.75584864616394 seconds)\n","| epoch 039:    100 / 1131 loss=3.037, nll_loss=1.496, ppl=2.82, wps=5219, ups=2, wpb=3448.396, bsz=137.426, num_updates=43079, lr=0.000152359, gnorm=0.738, clip=0.000, oom=0.000, wall=4618, train_wall=27254\n","| epoch 039:    200 / 1131 loss=3.046, nll_loss=1.507, ppl=2.84, wps=5300, ups=2, wpb=3492.080, bsz=145.791, num_updates=43179, lr=0.000152182, gnorm=0.730, clip=0.000, oom=0.000, wall=4684, train_wall=27319\n","| epoch 039:    300 / 1131 loss=3.057, nll_loss=1.519, ppl=2.87, wps=5321, ups=2, wpb=3504.498, bsz=142.299, num_updates=43279, lr=0.000152006, gnorm=0.735, clip=0.000, oom=0.000, wall=4750, train_wall=27385\n","| epoch 039:    400 / 1131 loss=3.060, nll_loss=1.523, ppl=2.87, wps=5317, ups=2, wpb=3493.481, bsz=144.020, num_updates=43379, lr=0.000151831, gnorm=0.736, clip=0.000, oom=0.000, wall=4815, train_wall=27449\n","| epoch 039:    500 / 1131 loss=3.066, nll_loss=1.530, ppl=2.89, wps=5328, ups=2, wpb=3501.449, bsz=143.952, num_updates=43479, lr=0.000151656, gnorm=0.737, clip=0.000, oom=0.000, wall=4881, train_wall=27514\n","| epoch 039:    600 / 1131 loss=3.070, nll_loss=1.534, ppl=2.90, wps=5337, ups=2, wpb=3504.606, bsz=145.052, num_updates=43579, lr=0.000151482, gnorm=0.737, clip=0.000, oom=0.000, wall=4946, train_wall=27579\n","| epoch 039:    700 / 1131 loss=3.074, nll_loss=1.540, ppl=2.91, wps=5337, ups=2, wpb=3501.014, bsz=143.966, num_updates=43679, lr=0.000151309, gnorm=0.740, clip=0.000, oom=0.000, wall=5012, train_wall=27644\n","| epoch 039:    800 / 1131 loss=3.075, nll_loss=1.541, ppl=2.91, wps=5341, ups=2, wpb=3502.715, bsz=144.979, num_updates=43779, lr=0.000151136, gnorm=0.740, clip=0.000, oom=0.000, wall=5077, train_wall=27709\n","| epoch 039:    900 / 1131 loss=3.079, nll_loss=1.546, ppl=2.92, wps=5343, ups=2, wpb=3506.150, bsz=143.698, num_updates=43879, lr=0.000150963, gnorm=0.741, clip=0.000, oom=0.000, wall=5143, train_wall=27774\n","| epoch 039:   1000 / 1131 loss=3.082, nll_loss=1.549, ppl=2.93, wps=5333, ups=2, wpb=3497.826, bsz=142.009, num_updates=43979, lr=0.000150792, gnorm=0.744, clip=0.000, oom=0.000, wall=5208, train_wall=27839\n","| epoch 039:   1100 / 1131 loss=3.084, nll_loss=1.551, ppl=2.93, wps=5330, ups=2, wpb=3494.713, bsz=141.885, num_updates=44079, lr=0.000150621, gnorm=0.744, clip=0.000, oom=0.000, wall=5274, train_wall=27904\n","| epoch 039 | loss 3.086 | nll_loss 1.553 | ppl 2.93 | wps 5328 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 44109 | lr 0.000150569 | gnorm 0.745 | clip 0.000 | oom 0.000 | wall 5293 | train_wall 27923\n","| epoch 039 | valid on 'valid' subset | loss 3.920 | nll_loss 2.357 | ppl 5.12 | num_updates 44109 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint39.pt (epoch 39 @ 44109 updates) (writing took 4.627822637557983 seconds)\n","| epoch 040:    100 / 1131 loss=3.048, nll_loss=1.506, ppl=2.84, wps=5210, ups=2, wpb=3412.040, bsz=123.723, num_updates=44210, lr=0.000150397, gnorm=0.753, clip=0.000, oom=0.000, wall=5376, train_wall=27988\n","| epoch 040:    200 / 1131 loss=3.039, nll_loss=1.496, ppl=2.82, wps=5247, ups=2, wpb=3427.199, bsz=132.697, num_updates=44310, lr=0.000150227, gnorm=0.747, clip=0.000, oom=0.000, wall=5441, train_wall=28053\n","| epoch 040:    300 / 1131 loss=3.045, nll_loss=1.503, ppl=2.83, wps=5265, ups=2, wpb=3446.910, bsz=131.907, num_updates=44410, lr=0.000150058, gnorm=0.747, clip=0.000, oom=0.000, wall=5507, train_wall=28118\n","| epoch 040:    400 / 1131 loss=3.056, nll_loss=1.516, ppl=2.86, wps=5291, ups=2, wpb=3465.671, bsz=131.070, num_updates=44510, lr=0.000149889, gnorm=0.749, clip=0.000, oom=0.000, wall=5573, train_wall=28183\n","| epoch 040:    500 / 1131 loss=3.061, nll_loss=1.522, ppl=2.87, wps=5297, ups=2, wpb=3467.411, bsz=132.772, num_updates=44610, lr=0.000149721, gnorm=0.752, clip=0.000, oom=0.000, wall=5638, train_wall=28248\n","| epoch 040:    600 / 1131 loss=3.061, nll_loss=1.523, ppl=2.87, wps=5300, ups=2, wpb=3469.631, bsz=135.493, num_updates=44710, lr=0.000149554, gnorm=0.751, clip=0.000, oom=0.000, wall=5704, train_wall=28313\n","| epoch 040:    700 / 1131 loss=3.061, nll_loss=1.523, ppl=2.87, wps=5303, ups=2, wpb=3474.101, bsz=137.699, num_updates=44810, lr=0.000149387, gnorm=0.749, clip=0.000, oom=0.000, wall=5769, train_wall=28378\n","| epoch 040:    800 / 1131 loss=3.065, nll_loss=1.528, ppl=2.88, wps=5310, ups=2, wpb=3478.930, bsz=138.286, num_updates=44910, lr=0.00014922, gnorm=0.750, clip=0.000, oom=0.000, wall=5835, train_wall=28443\n","| epoch 040:    900 / 1131 loss=3.068, nll_loss=1.532, ppl=2.89, wps=5310, ups=2, wpb=3476.736, bsz=138.982, num_updates=45010, lr=0.000149055, gnorm=0.751, clip=0.000, oom=0.000, wall=5900, train_wall=28508\n","| epoch 040:   1000 / 1131 loss=3.072, nll_loss=1.537, ppl=2.90, wps=5315, ups=2, wpb=3479.652, bsz=139.388, num_updates=45110, lr=0.000148889, gnorm=0.751, clip=0.000, oom=0.000, wall=5966, train_wall=28573\n","| epoch 040:   1100 / 1131 loss=3.074, nll_loss=1.540, ppl=2.91, wps=5326, ups=2, wpb=3491.003, bsz=141.856, num_updates=45210, lr=0.000148725, gnorm=0.749, clip=0.000, oom=0.000, wall=6032, train_wall=28638\n","| epoch 040 | loss 3.075 | nll_loss 1.540 | ppl 2.91 | wps 5325 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 45240 | lr 0.000148675 | gnorm 0.749 | clip 0.000 | oom 0.000 | wall 6052 | train_wall 28658\n","| epoch 040 | valid on 'valid' subset | loss 3.929 | nll_loss 2.365 | ppl 5.15 | num_updates 45240 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint40.pt (epoch 40 @ 45240 updates) (writing took 4.616022109985352 seconds)\n","| epoch 041:    100 / 1131 loss=3.024, nll_loss=1.482, ppl=2.79, wps=5344, ups=2, wpb=3551.337, bsz=148.356, num_updates=45341, lr=0.00014851, gnorm=0.721, clip=0.000, oom=0.000, wall=6136, train_wall=28725\n","| epoch 041:    200 / 1131 loss=3.023, nll_loss=1.481, ppl=2.79, wps=5327, ups=2, wpb=3516.055, bsz=146.070, num_updates=45441, lr=0.000148346, gnorm=0.729, clip=0.000, oom=0.000, wall=6202, train_wall=28790\n","| epoch 041:    300 / 1131 loss=3.024, nll_loss=1.482, ppl=2.79, wps=5322, ups=2, wpb=3501.797, bsz=147.402, num_updates=45541, lr=0.000148183, gnorm=0.733, clip=0.000, oom=0.000, wall=6267, train_wall=28854\n","| epoch 041:    400 / 1131 loss=3.031, nll_loss=1.490, ppl=2.81, wps=5337, ups=2, wpb=3513.100, bsz=146.015, num_updates=45641, lr=0.000148021, gnorm=0.734, clip=0.000, oom=0.000, wall=6333, train_wall=28920\n","| epoch 041:    500 / 1131 loss=3.039, nll_loss=1.499, ppl=2.83, wps=5346, ups=2, wpb=3520.152, bsz=144.094, num_updates=45741, lr=0.000147859, gnorm=0.736, clip=0.000, oom=0.000, wall=6399, train_wall=28985\n","| epoch 041:    600 / 1131 loss=3.044, nll_loss=1.505, ppl=2.84, wps=5346, ups=2, wpb=3517.977, bsz=144.930, num_updates=45841, lr=0.000147697, gnorm=0.741, clip=0.000, oom=0.000, wall=6465, train_wall=29050\n","| epoch 041:    700 / 1131 loss=3.048, nll_loss=1.510, ppl=2.85, wps=5333, ups=2, wpb=3503.223, bsz=144.341, num_updates=45941, lr=0.000147537, gnorm=0.744, clip=0.000, oom=0.000, wall=6530, train_wall=29115\n","| epoch 041:    800 / 1131 loss=3.048, nll_loss=1.510, ppl=2.85, wps=5327, ups=2, wpb=3496.377, bsz=145.517, num_updates=46041, lr=0.000147376, gnorm=0.747, clip=0.000, oom=0.000, wall=6595, train_wall=29179\n","| epoch 041:    900 / 1131 loss=3.054, nll_loss=1.516, ppl=2.86, wps=5325, ups=2, wpb=3493.572, bsz=143.679, num_updates=46141, lr=0.000147217, gnorm=0.750, clip=0.000, oom=0.000, wall=6660, train_wall=29244\n","| epoch 041:   1000 / 1131 loss=3.059, nll_loss=1.521, ppl=2.87, wps=5319, ups=2, wpb=3489.206, bsz=142.009, num_updates=46241, lr=0.000147057, gnorm=0.752, clip=0.000, oom=0.000, wall=6726, train_wall=29309\n","| epoch 041:   1100 / 1131 loss=3.063, nll_loss=1.526, ppl=2.88, wps=5325, ups=2, wpb=3491.368, bsz=142.052, num_updates=46341, lr=0.000146898, gnorm=0.752, clip=0.000, oom=0.000, wall=6791, train_wall=29374\n","| epoch 041 | loss 3.065 | nll_loss 1.528 | ppl 2.88 | wps 5326 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 46371 | lr 0.000146851 | gnorm 0.753 | clip 0.000 | oom 0.000 | wall 6811 | train_wall 29393\n","| epoch 041 | valid on 'valid' subset | loss 3.926 | nll_loss 2.356 | ppl 5.12 | num_updates 46371 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint41.pt (epoch 41 @ 46371 updates) (writing took 4.914798259735107 seconds)\n","| epoch 042:    100 / 1131 loss=3.019, nll_loss=1.474, ppl=2.78, wps=5284, ups=2, wpb=3474.871, bsz=136.634, num_updates=46472, lr=0.000146691, gnorm=0.742, clip=0.000, oom=0.000, wall=6895, train_wall=29459\n","| epoch 042:    200 / 1131 loss=3.022, nll_loss=1.477, ppl=2.78, wps=5293, ups=2, wpb=3466.796, bsz=135.363, num_updates=46572, lr=0.000146534, gnorm=0.743, clip=0.000, oom=0.000, wall=6960, train_wall=29524\n","| epoch 042:    300 / 1131 loss=3.032, nll_loss=1.489, ppl=2.81, wps=5294, ups=2, wpb=3454.854, bsz=136.133, num_updates=46672, lr=0.000146377, gnorm=0.751, clip=0.000, oom=0.000, wall=7025, train_wall=29588\n","| epoch 042:    400 / 1131 loss=3.036, nll_loss=1.493, ppl=2.82, wps=5292, ups=2, wpb=3454.192, bsz=133.845, num_updates=46772, lr=0.00014622, gnorm=0.754, clip=0.000, oom=0.000, wall=7090, train_wall=29653\n","| epoch 042:    500 / 1131 loss=3.040, nll_loss=1.498, ppl=2.82, wps=5307, ups=2, wpb=3468.475, bsz=134.180, num_updates=46872, lr=0.000146064, gnorm=0.755, clip=0.000, oom=0.000, wall=7156, train_wall=29718\n","| epoch 042:    600 / 1131 loss=3.044, nll_loss=1.503, ppl=2.83, wps=5312, ups=2, wpb=3472.639, bsz=133.617, num_updates=46972, lr=0.000145908, gnorm=0.757, clip=0.000, oom=0.000, wall=7221, train_wall=29783\n","| epoch 042:    700 / 1131 loss=3.045, nll_loss=1.505, ppl=2.84, wps=5308, ups=2, wpb=3471.826, bsz=136.331, num_updates=47072, lr=0.000145753, gnorm=0.757, clip=0.000, oom=0.000, wall=7287, train_wall=29848\n","| epoch 042:    800 / 1131 loss=3.047, nll_loss=1.507, ppl=2.84, wps=5324, ups=2, wpb=3488.954, bsz=137.788, num_updates=47172, lr=0.000145599, gnorm=0.754, clip=0.000, oom=0.000, wall=7353, train_wall=29914\n","| epoch 042:    900 / 1131 loss=3.049, nll_loss=1.510, ppl=2.85, wps=5319, ups=2, wpb=3483.915, bsz=139.747, num_updates=47272, lr=0.000145445, gnorm=0.755, clip=0.000, oom=0.000, wall=7418, train_wall=29978\n","| epoch 042:   1000 / 1131 loss=3.051, nll_loss=1.512, ppl=2.85, wps=5320, ups=2, wpb=3483.971, bsz=140.899, num_updates=47372, lr=0.000145291, gnorm=0.755, clip=0.000, oom=0.000, wall=7484, train_wall=30043\n","| epoch 042:   1100 / 1131 loss=3.054, nll_loss=1.515, ppl=2.86, wps=5321, ups=2, wpb=3489.008, bsz=141.238, num_updates=47472, lr=0.000145138, gnorm=0.755, clip=0.000, oom=0.000, wall=7550, train_wall=30109\n","| epoch 042 | loss 3.054 | nll_loss 1.516 | ppl 2.86 | wps 5323 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 47502 | lr 0.000145092 | gnorm 0.755 | clip 0.000 | oom 0.000 | wall 7570 | train_wall 30129\n","| epoch 042 | valid on 'valid' subset | loss 3.944 | nll_loss 2.377 | ppl 5.19 | num_updates 47502 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint42.pt (epoch 42 @ 47502 updates) (writing took 4.412971258163452 seconds)\n","| epoch 043:    100 / 1131 loss=3.023, nll_loss=1.480, ppl=2.79, wps=5342, ups=2, wpb=3535.822, bsz=139.881, num_updates=47603, lr=0.000144938, gnorm=0.737, clip=0.000, oom=0.000, wall=7654, train_wall=30195\n","| epoch 043:    200 / 1131 loss=3.015, nll_loss=1.471, ppl=2.77, wps=5300, ups=2, wpb=3490.214, bsz=153.075, num_updates=47703, lr=0.000144786, gnorm=0.741, clip=0.000, oom=0.000, wall=7720, train_wall=30260\n","| epoch 043:    300 / 1131 loss=3.021, nll_loss=1.478, ppl=2.78, wps=5296, ups=2, wpb=3472.080, bsz=146.179, num_updates=47803, lr=0.000144635, gnorm=0.750, clip=0.000, oom=0.000, wall=7785, train_wall=30324\n","| epoch 043:    400 / 1131 loss=3.023, nll_loss=1.479, ppl=2.79, wps=5305, ups=2, wpb=3480.132, bsz=140.948, num_updates=47903, lr=0.000144484, gnorm=0.752, clip=0.000, oom=0.000, wall=7850, train_wall=30390\n","| epoch 043:    500 / 1131 loss=3.026, nll_loss=1.483, ppl=2.80, wps=5309, ups=2, wpb=3486.631, bsz=139.289, num_updates=48003, lr=0.000144333, gnorm=0.753, clip=0.000, oom=0.000, wall=7916, train_wall=30455\n","| epoch 043:    600 / 1131 loss=3.032, nll_loss=1.490, ppl=2.81, wps=5311, ups=2, wpb=3485.351, bsz=139.754, num_updates=48103, lr=0.000144183, gnorm=0.756, clip=0.000, oom=0.000, wall=7982, train_wall=30520\n","| epoch 043:    700 / 1131 loss=3.035, nll_loss=1.493, ppl=2.81, wps=5312, ups=2, wpb=3479.439, bsz=140.257, num_updates=48203, lr=0.000144033, gnorm=0.758, clip=0.000, oom=0.000, wall=8046, train_wall=30584\n","| epoch 043:    800 / 1131 loss=3.038, nll_loss=1.497, ppl=2.82, wps=5318, ups=2, wpb=3483.483, bsz=141.831, num_updates=48303, lr=0.000143884, gnorm=0.759, clip=0.000, oom=0.000, wall=8112, train_wall=30649\n","| epoch 043:    900 / 1131 loss=3.040, nll_loss=1.500, ppl=2.83, wps=5317, ups=2, wpb=3483.055, bsz=141.042, num_updates=48403, lr=0.000143735, gnorm=0.759, clip=0.000, oom=0.000, wall=8177, train_wall=30714\n","| epoch 043:   1000 / 1131 loss=3.043, nll_loss=1.503, ppl=2.83, wps=5323, ups=2, wpb=3487.145, bsz=140.970, num_updates=48503, lr=0.000143587, gnorm=0.760, clip=0.000, oom=0.000, wall=8243, train_wall=30779\n","| epoch 043:   1100 / 1131 loss=3.045, nll_loss=1.505, ppl=2.84, wps=5329, ups=2, wpb=3493.742, bsz=141.848, num_updates=48603, lr=0.000143439, gnorm=0.759, clip=0.000, oom=0.000, wall=8309, train_wall=30844\n","| epoch 043 | loss 3.044 | nll_loss 1.504 | ppl 2.84 | wps 5325 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 48633 | lr 0.000143395 | gnorm 0.759 | clip 0.000 | oom 0.000 | wall 8329 | train_wall 30864\n","| epoch 043 | valid on 'valid' subset | loss 3.938 | nll_loss 2.370 | ppl 5.17 | num_updates 48633 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint43.pt (epoch 43 @ 48633 updates) (writing took 4.770414352416992 seconds)\n","| epoch 044:    100 / 1131 loss=2.993, nll_loss=1.443, ppl=2.72, wps=5304, ups=2, wpb=3522.752, bsz=134.495, num_updates=48734, lr=0.000143246, gnorm=0.745, clip=0.000, oom=0.000, wall=8413, train_wall=30930\n","| epoch 044:    200 / 1131 loss=2.994, nll_loss=1.444, ppl=2.72, wps=5277, ups=2, wpb=3462.562, bsz=136.199, num_updates=48834, lr=0.0001431, gnorm=0.753, clip=0.000, oom=0.000, wall=8478, train_wall=30995\n","| epoch 044:    300 / 1131 loss=2.998, nll_loss=1.450, ppl=2.73, wps=5268, ups=2, wpb=3452.455, bsz=139.000, num_updates=48934, lr=0.000142953, gnorm=0.755, clip=0.000, oom=0.000, wall=8544, train_wall=31060\n","| epoch 044:    400 / 1131 loss=3.000, nll_loss=1.454, ppl=2.74, wps=5300, ups=2, wpb=3479.928, bsz=149.663, num_updates=49034, lr=0.000142808, gnorm=0.751, clip=0.000, oom=0.000, wall=8610, train_wall=31125\n","| epoch 044:    500 / 1131 loss=3.010, nll_loss=1.465, ppl=2.76, wps=5317, ups=2, wpb=3496.986, bsz=146.329, num_updates=49134, lr=0.000142662, gnorm=0.752, clip=0.000, oom=0.000, wall=8676, train_wall=31191\n","| epoch 044:    600 / 1131 loss=3.015, nll_loss=1.470, ppl=2.77, wps=5329, ups=2, wpb=3507.433, bsz=145.569, num_updates=49234, lr=0.000142517, gnorm=0.751, clip=0.000, oom=0.000, wall=8742, train_wall=31256\n","| epoch 044:    700 / 1131 loss=3.021, nll_loss=1.478, ppl=2.79, wps=5335, ups=2, wpb=3507.509, bsz=145.437, num_updates=49334, lr=0.000142373, gnorm=0.753, clip=0.000, oom=0.000, wall=8807, train_wall=31321\n","| epoch 044:    800 / 1131 loss=3.024, nll_loss=1.481, ppl=2.79, wps=5329, ups=2, wpb=3501.464, bsz=143.589, num_updates=49434, lr=0.000142229, gnorm=0.755, clip=0.000, oom=0.000, wall=8873, train_wall=31386\n","| epoch 044:    900 / 1131 loss=3.024, nll_loss=1.481, ppl=2.79, wps=5317, ups=2, wpb=3491.553, bsz=144.123, num_updates=49534, lr=0.000142085, gnorm=0.756, clip=0.000, oom=0.000, wall=8938, train_wall=31450\n","| epoch 044:   1000 / 1131 loss=3.028, nll_loss=1.485, ppl=2.80, wps=5310, ups=2, wpb=3485.258, bsz=142.600, num_updates=49634, lr=0.000141942, gnorm=0.759, clip=0.000, oom=0.000, wall=9003, train_wall=31515\n","| epoch 044:   1100 / 1131 loss=3.032, nll_loss=1.491, ppl=2.81, wps=5320, ups=2, wpb=3491.745, bsz=141.340, num_updates=49734, lr=0.000141799, gnorm=0.759, clip=0.000, oom=0.000, wall=9069, train_wall=31580\n","| epoch 044 | loss 3.034 | nll_loss 1.492 | ppl 2.81 | wps 5322 | ups 2 | wpb 3491.701 | bsz 141.679 | num_updates 49764 | lr 0.000141756 | gnorm 0.759 | clip 0.000 | oom 0.000 | wall 9088 | train_wall 31600\n","| epoch 044 | valid on 'valid' subset | loss 3.924 | nll_loss 2.361 | ppl 5.14 | num_updates 49764 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint44.pt (epoch 44 @ 49764 updates) (writing took 4.733439922332764 seconds)\n","| epoch 045:    100 / 1131 loss=2.990, nll_loss=1.442, ppl=2.72, wps=5322, ups=2, wpb=3536.970, bsz=143.129, num_updates=49865, lr=0.000141613, gnorm=0.741, clip=0.000, oom=0.000, wall=9173, train_wall=31666\n","| epoch 045:    200 / 1131 loss=2.984, nll_loss=1.435, ppl=2.70, wps=5331, ups=2, wpb=3538.562, bsz=150.965, num_updates=49965, lr=0.000141471, gnorm=0.744, clip=0.000, oom=0.000, wall=9239, train_wall=31732\n","| epoch 045 | loss 2.984 | nll_loss 1.435 | ppl 2.70 | wps 5325 | ups 2 | wpb 3526.945 | bsz 148.576 | num_updates 50000 | lr 0.000141421 | gnorm 0.746 | clip 0.000 | oom 0.000 | wall 9262 | train_wall 31755\n","| epoch 045 | valid on 'valid' subset | loss 3.941 | nll_loss 2.374 | ppl 5.18 | num_updates 50000 | best_loss 3.88941\n","| saved checkpoint /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last.pt (epoch 45 @ 50000 updates) (writing took 2.2322683334350586 seconds)\n","| done training in 9275.3 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RTd14wsDKZ4s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"978103f3-b80b-490c-e31c-40d6c42505ce","executionInfo":{"status":"ok","timestamp":1574181314593,"user_tz":-540,"elapsed":179430,"user":{"displayName":"조영인","photoUrl":"","userId":"05449711691851181001"}}},"source":["!python scripts/average_checkpoints.py --inputs \"{SAVE}\" \\\n","    --num-epoch-checkpoints 10 --output \"{SAVE}/checkpoint_last10_avg.pt\"\n","\n","# Evaluation\n","!CUDA_VISIBLE_DEVICES=0 fairseq-generate data-bin/iwslt14.tokenized.de-en --path \"{SAVE}/checkpoint_last10_avg.pt\" --batch-size 128 --beam 4 --remove-bpe --lenpen 1 --gen-subset test --quiet "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt'], num_epoch_checkpoints=10, num_update_checkpoints=None, output='/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last10_avg.pt')\n","averaging checkpoints:  ['/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint44.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint43.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint42.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint41.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint40.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint39.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint38.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint37.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint36.pt', '/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint35.pt']\n","Finished writing averaged checkpoint to /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last10_avg.pt.\n","Namespace(beam=4, bpe=None, cpu=False, criterion='cross_entropy', data='data-bin/iwslt14.tokenized.de-en', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1.0, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='/content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last10_avg.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=True, raw_text=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, results_path=None, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tbmf_wrapper=False, temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n","| [de] dictionary: 8848 types\n","| [en] dictionary: 6632 types\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.de\n","| loaded 6750 examples from: data-bin/iwslt14.tokenized.de-en/test.de-en.en\n","| data-bin/iwslt14.tokenized.de-en test de-en 6750 examples\n","| loading model(s) from /content/gdrive/My Drive/colab/payless/save_dev3_non_glu/dynamic_conv_iwslt/checkpoint_last10_avg.pt\n","| Translated 6750 sentences (147913 tokens) in 77.7s (86.91 sentences/s, 1904.44 tokens/s)\n","| Generate test with beam=4: BLEU4 = 34.61, 69.1/43.4/29.3/20.1 (BP=0.949, ratio=0.950, syslen=124662, reflen=131161)\n"],"name":"stdout"}]}]}